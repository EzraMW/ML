{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EzraMW/ML/blob/main/NLP_HW_PMI%2C_Bayes%2C_Lift%2C_etc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yLgT8Mh8X5Ea"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from collections import Counter\n",
        "\n",
        "# fetch 20 newsgroups dataset\n",
        "#newsgroups_data = fetch_20newsgroups(subset='train')\n",
        "cats = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
        "newsgroups_data = fetch_20newsgroups(subset='train',\n",
        "                                      remove=('headers', 'footers', 'quotes'),categories=cats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmKlj5ef1cLw"
      },
      "source": [
        "Note that for now I only look at one category. As PMI is unsupervised, this is not a problem at all. I did this as the code already isn't super-fast to run.  Here is how GPT thought we should parse the corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZWl8ZUPBH1w",
        "outputId": "97de82e3-ceb5-4080-a6dd-040e922406de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PMI"
      ],
      "metadata": {
        "id": "wtvhwkCq37x0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYpEn_Bu1WGT"
      },
      "outputs": [],
      "source": [
        "docs = newsgroups_data['data']\n",
        "\n",
        "# Preprocessing - convert docs to list of words\n",
        "docs = [[word.lower() for word in sentence.split() if word not in stop_words] for sentence in docs]\n",
        "\n",
        "# Create a word frequency dictionary\n",
        "word_freq = Counter([word for doc in docs for word in doc])\n",
        "\n",
        "# Filter words that appear less than 10 times\n",
        "word_freq = {word: freq for word, freq in word_freq.items() if freq >= 30}\n",
        "\n",
        "# Calculate number of docs\n",
        "N = len(docs)\n",
        "\n",
        "# Create a set of words to store words that have already been processed\n",
        "processed_words = set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzX-4TT6ZL7s"
      },
      "source": [
        "This code has issues, but works. However, note that sometimes it gives a division by zero error, and weeds out terms that appear less than 10 times.  It also doesn't take out stopwords.  Now for the code. It has quite the loop within a loop using a dictionary (hash-table), but here it is: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XzBH66BZgBF"
      },
      "source": [
        "I have some questions:\n",
        "\n",
        "1.   Do these terms help the classification task you started last week?\n",
        "2.   Maybe other parameters work better?   Please check and justify different:\n",
        " , if taking out stopwords (or other \n",
        "\n",
        "*   Values for the frequency value (here 10), but 30 runs *much* faster\n",
        "*   Only use those words with a PMI over a certain threshold that you experimentally tinker with. Note that this threshold is like confidence in the slides\n",
        "*   Take out the stopwords first.\n",
        "\n",
        "Now print those most correlated words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERNwMhuH4WdL"
      },
      "source": [
        "What does this output mean to you?  I don't mean in a theoretical sense, but what can you do with it to help the classification performance?  We'll discuss in class.  Also, please output the most correlated words with the following list:\n",
        "\n",
        "space, god, time, good, long, use, point, program, nasa, software, shuttle, moon, launch, data, orbit, lunar, graphics, software, image, earth, program, computer, christian"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['space', 'god', 'time', 'good', 'long', 'use', 'point', 'program', 'nasa', 'software', 'shuttle', 'moon', 'launch', 'data', 'orbit', 'lunar', 'graphics', 'software', 'image', 'earth', 'program', 'computer', 'christian']"
      ],
      "metadata": {
        "id": "SvhcuCA-0tWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-428QVAGXxBb",
        "outputId": "8988c8ed-6530-43eb-84f6-22ba2bb25a0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-d335e83517b7>:19: RuntimeWarning: divide by zero encountered in log\n",
            "  pmi = np.log(p_w1_w2 / (p_w1 * p_w2))\n"
          ]
        }
      ],
      "source": [
        "#Calculate PMI for each word-word pair\n",
        "\n",
        "pmi_dict = {}\n",
        "for i, doc1 in enumerate(docs):\n",
        "    for w1 in set(doc1) & set(words):\n",
        "        if w1 in processed_words:\n",
        "            continue\n",
        "        processed_words.add(w1)\n",
        "        p_w1 = word_freq[w1] / N\n",
        "        for j, doc2 in enumerate(docs):\n",
        "            for w2 in set(doc2) & set(word_freq.keys()):\n",
        "                if w2 in processed_words or w1 == w2:\n",
        "                    continue\n",
        "                key = (w1, w2)\n",
        "                if key in pmi_dict:\n",
        "                    continue\n",
        "                p_w2 = word_freq[w2] / N\n",
        "                p_w1_w2 = len([d for d in docs if w1 in d and w2 in d]) / N\n",
        "                pmi = np.log(p_w1_w2 / (p_w1 * p_w2))\n",
        "                pmi_dict[key] = pmi\n",
        "                pmi_dict[(w2, w1)] = pmi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2JmHpH_nW91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d03bbc8-efb1-435a-e802-b8c8271ea8e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most correlated words for 'space': [('space.', 0.5620154199129188), ('orbiting', 0.3994964904151439), ('office', 0.37611604177108027), ('exploration', 0.3613447244507679), ('fuel', 0.33887186859870927), ('agency', 0.33887186859870927), ('other', 0.29631225417991336), ('systems,', 0.27433334746113797), ('release', 0.27433334746113797), ('u.s.', 0.23177373304234192)]\n",
            "Most correlated words for 'god': [(\"god's\", 0.9207253289420209), ('people,', 0.8987464222232454), ('bible,', 0.8381218004068108), ('tells', 0.7761441001309131), ('do.', 0.7570959051602186), ('lord', 0.716424865429291), ('evil', 0.7009206788933258), ('life.', 0.6980757267610944), (\"one's\", 0.6911070574450008), ('exist', 0.6890258912411765)]\n",
            "Most correlated words for 'time': [('spend', 1.1422305625380738), ('systems,', 1.1104818642234935), ('knew', 1.1104818642234935), ('present', 1.0914336692527988), ('amount', 1.0845063778202328), ('difficult', 1.083082890035379), ('responsible', 1.0797102055567398), ('eventually', 1.041488992736542), ('behind', 1.0208697055338063), ('lost', 1.0151716844191687)]\n",
            "Most correlated words for 'good': [('eventually', 1.0892535636036398), ('good.', 1.0892535636036398), ('us,', 1.085339664282503), (\"one's\", 1.0247150424660685), ('changed', 1.0247150424660685), ('apply', 1.0022421866140099), ('expect', 1.0011845450558745), ('respect', 0.9487291354881465), ('worth', 0.9446723347925322), ('earlier', 0.9294048626617437)]\n",
            "Most correlated words for 'long': [('caused', 1.4359501899376996), ('hand,', 1.3240322737337145), ('supported', 1.2668738598937659), ('plan', 1.2668738598937659), ('especially', 1.2485247212255692), ('offer', 1.2340840370707749), ('program,', 1.2340840370707749), ('them,', 1.2260518653735106), ('shows', 1.21280663862349), ('bring', 1.21280663862349)]\n",
            "Most correlated words for 'use': [('plan', 0.9023761902738242), ('years,', 0.8978410351084328), ('release', 0.8079847059865719), ('particularly', 0.7707405328142009), ('(not', 0.7547401914677598), ('short', 0.7308727100611161), ('allowed', 0.7294223834834698), ('product', 0.7082201758328668), ('30', 0.7034468970802092), ('gives', 0.6853116850359965)]\n",
            "Most correlated words for 'point': [('necessarily', 1.3230208622889061), ('accepted', 1.3134514112727553), ('regarding', 1.2806615884497643), ('point.', 1.2489128901351843), ('admit', 1.233408703599219), ('intended', 1.2201634768491982), ('red', 1.2006188807762281), ('none', 1.184618539429787), ('function', 1.1778388524444083), ('reasons', 1.1778388524444083)]\n",
            "Most correlated words for 'program': [('office', 1.1464442100339631), ('program,', 1.1247042233975573), ('program.', 1.077451338547012), ('space.', 1.0774513385470117), ('internet', 0.9952132403100399), ('screen', 0.9641226532400087), ('final', 0.9477735152384792), ('plus', 0.9477735152384792), ('systems,', 0.9211052681563178), ('top', 0.9211052681563178)]\n",
            "Most correlated words for 'nasa': [('safety', 1.6310431259965976), ('ames', 1.6258951094791962), ('exploration', 1.18903314731036), ('perfect', 1.067441436723951), ('other', 1.0219790626471938), ('press', 1.0219790626471936), ('agency', 1.0219790626471936), ('u.s.', 0.9574405415096227), ('washington,', 0.9574405415096225), ('variety', 0.9266688828428689)]\n",
            "Most correlated words for 'software': [('engineering', 1.1560510445271552), ('frame', 1.0972857353009038), ('other', 1.0610826866369432), ('digital', 1.0559675859701727), ('ibm', 0.9759248782966363), ('variety', 0.9294048626617436), ('product', 0.9294048626617436), ('advanced', 0.9203550271418258), ('plus', 0.9203550271418258), ('directly', 0.9130110528860671)]\n",
            "Most correlated words for 'shuttle': [('exploration', 1.6427762556843153), ('office', 1.5447150425081004), ('fuel', 1.4757221710211488), ('solid', 1.350559028067143), ('resources', 1.3375718325403316), ('elements', 1.3058231342257514), ('facility', 1.3058231342257514), ('service', 1.2891362154407369), ('return', 1.2525786197069393), ('other', 1.2525786197069393)]\n",
            "Most correlated words for 'moon': [('base', 1.601159056228981), ('plan', 1.5028139727295022), ('spend', 1.228862093089623), ('billion', 1.2208299213923588), ('saturn', 1.207584694642338), ('larger', 1.1971133947750427), ('orbiting', 1.0385083645984043), ('space,', 1.0385083645984043), ('fuel', 1.0385083645984043), ('went', 1.0165294578796291)]\n",
            "Most correlated words for 'launch': [('exploration', 1.068108834374695), ('atmosphere', 1.0681088343746947), ('orbit.', 0.9771370561689684), ('agency', 0.9627483187168687), ('saturn', 0.9270302361147895), ('payload', 0.9270302361147895), ('delta', 0.8674381389125438), ('space.', 0.8449652830604852), ('orbiting', 0.8449652830604852), ('titan', 0.8449652830604852)]\n",
            "Most correlated words for 'data': [('data,', 1.008915852029698), ('particularly', 0.8936498073824684), ('advanced', 0.8598199428640636), ('global', 0.846396922531923), ('distributed', 0.772288950378201), ('elements', 0.6948470244047219), ('release', 0.6948470244047219), ('top', 0.6900508521412289), ('range', 0.6881729173170288), ('space.', 0.6640753657379683)]\n",
            "Most correlated words for 'orbit': [('orbiting', 1.878259019350225), ('fuel', 1.878259019350225), ('delta', 1.7829488395459), ('orbit.', 1.6919770613401734), ('planet', 1.6876386597415751), ('saturn', 1.6418702412859947), ('propulsion', 1.5753094747676555), ('30', 1.5598052882316906), ('other', 1.5598052882316906), ('gravity', 1.5234376440608153)]\n",
            "Most correlated words for 'lunar': [('exploration', 1.5563026576804881), ('fuel', 1.484558752821647), ('gravity', 1.3304080729943886), ('orbiting', 1.2838880573594957), ('15', 1.222194488354156), ('plan', 1.188577877555171), ('global', 1.1661050217031126), ('low', 1.0474992792952653), ('space.', 1.0325736290785898), ('u.s.', 1.0145551235759114)]\n",
            "Most correlated words for 'graphics': [('programming', 1.116469906068116), ('newsgroup', 1.002059554890372), ('shareware', 0.9783195675872989), ('card', 0.9341483492741616), ('vga', 0.9341483492741616), ('routines', 0.915799210605965), ('fast', 0.8933263547539063), ('handle', 0.8859462474562837), ('interface', 0.851777351841034), ('j.', 0.7597949621293839)]\n",
            "Most correlated words for 'software': [('engineering', 1.1560510445271552), ('frame', 1.0972857353009038), ('other', 1.0610826866369432), ('digital', 1.0559675859701727), ('ibm', 0.9759248782966363), ('variety', 0.9294048626617436), ('product', 0.9294048626617436), ('advanced', 0.9203550271418258), ('plus', 0.9203550271418258), ('directly', 0.9130110528860671)]\n",
            "Most correlated words for 'image': [('images,', 0.46738496981150174), ('other', 0.43921409284480534), ('function', 0.41181511865669107), ('is:', 0.4064242700218145), ('particularly', 0.4064242700218145), ('digital', 0.3651061206910836), ('screen', 0.3651061206910836), ('variety', 0.34390391304048057), ('global', 0.3338535771869791), ('program,', 0.3010637543639883)]\n",
            "Most correlated words for 'earth': [('orbiting', 1.7993737192133004), ('north', 1.5582116623964124), ('offer', 1.5254218395734214), ('materials', 1.4330485194424065), ('basic', 1.4265338384212125), ('saturn', 1.4088342613218117), ('elements', 1.3983629614545163), ('planet', 1.3675913027877626), ('beyond', 1.3652630130281715), ('c.', 1.3575409669342613)]\n",
            "Most correlated words for 'program': [('office', 1.1464442100339631), ('program,', 1.1247042233975573), ('program.', 1.077451338547012), ('space.', 1.0774513385470117), ('internet', 0.9952132403100399), ('screen', 0.9641226532400087), ('final', 0.9477735152384792), ('plus', 0.9477735152384792), ('systems,', 0.9211052681563178), ('top', 0.9211052681563178)]\n",
            "Most correlated words for 'computer': [('performance', 1.629424922509451), ('electronic', 1.5424135455198213), ('j.', 1.5424135455198211), ('product', 1.4471033657154964), ('program,', 1.404263207039004), ('digital', 1.3882628656925626), ('images,', 1.3882628656925626), ('(not', 1.3600919887258665), ('price', 1.332693014537752), ('advanced', 1.332693014537752)]\n",
            "Most correlated words for 'christian': [('reasons', 1.4613103923598456), ('christianity', 1.2810700017697154), ('refer', 1.2655658152337503), ('followers', 1.2655658152337503), ('hand,', 1.2581857079361278), ('ones', 1.2581857079361278), ('people,', 1.2523205884837296), ('christ', 1.2402480072494602), ('authority', 1.2327759924107593), ('\"what', 1.2327759924107593)]\n"
          ]
        }
      ],
      "source": [
        "num_correlated_words = 10\n",
        "for word in words:\n",
        "  correlated_words = sorted(pmi_dict.keys(), key=lambda x: pmi_dict[x], reverse=True)\n",
        "  correlated_words = [(w2, pmi_dict[(word, w2)]) for w1, w2 in correlated_words if w1 == word][:num_correlated_words]\n",
        "  print(f\"Most correlated words for '{word}': {correlated_words}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Univariate"
      ],
      "metadata": {
        "id": "0clVF0bCYdCS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see the top overall features based on Mutual Information, Chi Squared, and Anova see my previous homework here: https://github.com/EzraMW/ML/blob/main/Ezra_Wildes_20_newsgroups.ipynb"
      ],
      "metadata": {
        "id": "92MJDYH9Yh3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mutual Information, Bayes and Lift for Each Category"
      ],
      "metadata": {
        "id": "vUmeEK3W3_le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cats = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
        "newsgroups_train = fetch_20newsgroups(subset='train',\n",
        "                                      remove=('headers', 'footers', 'quotes'),categories=cats)\n",
        "vectorizer = CountVectorizer(stop_words=stop_words)\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)"
      ],
      "metadata": {
        "id": "daYUyCQ6q4z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most important Words for entire data set using mutual information"
      ],
      "metadata": {
        "id": "bcxBfKyvsUZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "mutual_info = mutual_info_classif(vectors, newsgroups_train.target)\n",
        "mscores = zip(vectorizer.get_feature_names_out(), mutual_info)\n",
        "print(\"Mutual Info Scores:\")\n",
        "ms = sorted(mscores, key=lambda x:x[1], reverse=True)\n",
        "for i in range(20):\n",
        "  print(ms[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDfYWJi1qyzL",
        "outputId": "cc76fda7-71c7-409c-e6a4-bbf6b6d20de5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mutual Info Scores:\n",
            "('space', 0.1173236239203111)\n",
            "('god', 0.08240250725184703)\n",
            "('graphics', 0.08049773882433058)\n",
            "('nasa', 0.055489959154984406)\n",
            "('jesus', 0.05333519728289461)\n",
            "('bible', 0.05004515233088479)\n",
            "('religion', 0.04976531130996275)\n",
            "('orbit', 0.049184367136139946)\n",
            "('people', 0.04861661784666319)\n",
            "('thanks', 0.04463381475169975)\n",
            "('christian', 0.044047732361940616)\n",
            "('launch', 0.04277924010634955)\n",
            "('program', 0.040848159552271314)\n",
            "('christians', 0.03895386885667414)\n",
            "('shuttle', 0.037867437032728296)\n",
            "('moon', 0.03768502661354253)\n",
            "('atheism', 0.03634392268281014)\n",
            "('file', 0.03534148343611571)\n",
            "('files', 0.03505449223777356)\n",
            "('religious', 0.035003673669855496)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find the label for each category"
      ],
      "metadata": {
        "id": "TdxFH0zLutyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20,30):\n",
        "  print(\"Label: \", newsgroups_train.target[i])\n",
        "  print(newsgroups_train.data[i][:100])\n",
        "  print(\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LscJ1hnQyQSv",
        "outputId": "7f3f9103-08df-42b7-a5eb-03ac58bc08c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label:  2\n",
            "\n",
            "\n",
            "\n",
            "If by that you mean anything on the GD approach, there was an article on\n",
            "it in a recent Avation W\n",
            " \n",
            "Label:  1\n",
            "\n",
            "The 68070 is a variation of the 68010 that was done a few years ago by\n",
            "the European partners of Mot\n",
            " \n",
            "Label:  3\n",
            "PSA 145:9  The LORD is good to all: and his  tender  mercies  are\n",
            "over all his works.\n",
            " \n",
            "Label:  3\n",
            "There has been a lot of discussion about Tyre.  In sum, Ezekiel prophesied\n",
            "that the place would be m\n",
            " \n",
            "Label:  1\n",
            "About a year ago I started work on a problem that appeared to\n",
            "be very simple and turned out to be qu\n",
            " \n",
            "Label:  1\n",
            "I need the file format for cc:Mail file formats - it seems to be PCX-based,\n",
            "but with a twist: only t\n",
            " \n",
            "Label:  2\n",
            "\n",
            " \n",
            "Label:  1\n",
            "I've got a 386 20Hz computer which is under warranty and my Trident\n",
            "8900C video card is starting to \n",
            " \n",
            "Label:  2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "Label:  3\n",
            "\n",
            "\tPlease do! And if you don't want to post it here, email to me\n",
            ":-) I don't know how this discussion\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = 0\n",
        "for i in range(len(newsgroups_train.data)):\n",
        "  if newsgroups_train.target[i] == label:\n",
        "    print(\"Label: \", label)\n",
        "    print(newsgroups_train.data[i])\n",
        "    print(\" \")\n",
        "    label += 1\n",
        "  if label == 5:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuoN6bGPsXdX",
        "outputId": "514893e0-720c-4d93-b563-9d1193c9c70d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label:  0\n",
            "I have a request for those who would like to see Charley Wingate\n",
            "respond to the \"Charley Challenges\" (and judging from my e-mail, there\n",
            "appear to be quite a few of you.)  \n",
            "\n",
            "It is clear that Mr. Wingate intends to continue to post tangential or\n",
            "unrelated articles while ingoring the Challenges themselves.  Between\n",
            "the last two re-postings of the Challenges, I noted perhaps a dozen or\n",
            "more posts by Mr. Wingate, none of which answered a single Challenge.  \n",
            "\n",
            "It seems unmistakable to me that Mr. Wingate hopes that the questions\n",
            "will just go away, and he is doing his level best to change the\n",
            "subject.  Given that this seems a rather common net.theist tactic, I\n",
            "would like to suggest that we impress upon him our desire for answers,\n",
            "in the following manner:\n",
            "\n",
            "1. Ignore any future articles by Mr. Wingate that do not address the\n",
            "Challenges, until he answers them or explictly announces that he\n",
            "refuses to do so.\n",
            "\n",
            "--or--\n",
            "\n",
            "2. If you must respond to one of his articles, include within it\n",
            "something similar to the following:\n",
            "\n",
            "    \"Please answer the questions posed to you in the Charley Challenges.\"\n",
            "\n",
            "Really, I'm not looking to humiliate anyone here, I just want some\n",
            "honest answers.  You wouldn't think that honesty would be too much to\n",
            "ask from a devout Christian, would you?  \n",
            "\n",
            "Nevermind, that was a rhetorical question.\n",
            " \n",
            "Label:  1\n",
            "\n",
            "Acorn Replay running on a 25MHz ARM 3 processor (the ARM 3 is about 20% slower\n",
            "than the ARM 6) does this in software (off a standard CD-ROM). 16 bit colour at\n",
            "about the same resolution (so what if the computer only has 8 bit colour\n",
            "support, real-time dithering too...). The 3D0/O is supposed to have a couple of\n",
            "DSPs - the ARM being used for housekeeping.\n",
            "\n",
            "\n",
            "A 25MHz ARM 6xx should clock around 20 ARM MIPS, say 18 flat out. Depends\n",
            "really on the surrounding system and whether you are talking ARM6x or ARM6xx\n",
            "(the latter has a cache, and so is essential to run at this kind of speed with\n",
            "slower memory).\n",
            "\n",
            "I'll stop saying things there 'cos I'll hopefully be working for ARM after\n",
            "graduation...\n",
            "\n",
            "Mike\n",
            "\n",
            "PS Don't pay heed to what reps from Philips say; if the 3D0/O doesn't beat the\n",
            "   pants off 3DI then I'll eat this postscript.\n",
            " \n",
            "Label:  2\n",
            "\n",
            "Their Hiten engineering-test mission spent a while in a highly eccentric\n",
            "Earth orbit doing lunar flybys, and then was inserted into lunar orbit\n",
            "using some very tricky gravity-assist-like maneuvering.  This meant that\n",
            "it would crash on the Moon eventually, since there is no such thing as\n",
            "a stable lunar orbit (as far as anyone knows), and I believe I recall\n",
            "hearing recently that it was about to happen.\n",
            " \n",
            "Label:  3\n",
            "DM> Fact or rumor....?  Madalyn Murray O'Hare an atheist who eliminated the\n",
            "DM> use of the bible reading and prayer in public schools 15 years ago is now\n",
            "DM> going to appear before the FCC with a petition to stop the reading of the\n",
            "DM> Gospel on the airways of America.  And she is also campaigning to remove\n",
            "DM> Christmas programs, songs, etc from the public schools.  If it is true\n",
            "DM> then mail to Federal Communications Commission 1919 H Street Washington DC\n",
            "DM> 20054 expressing your opposition to her request.  Reference Petition number\n",
            "\n",
            "DM> 2493.\n",
            "\n",
            "False.  This story has been going around for years.  There's not a drop of\n",
            "truth.  Note that I don't care for O'Hare (O'Hair?) myself, but this\n",
            "is one thing she's not guilty of.\n",
            "\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So 0 is Atheism, 1 is graphics, 2 is space, and 3 is Religion"
      ],
      "metadata": {
        "id": "t3yv9bJ3wn8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert Target for Label\n",
        "So for each category convert all target values in that category to 0 and all others to 1 so that we can do a this versus all others mutual information classifier"
      ],
      "metadata": {
        "id": "2OYqripMZIbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "atheism_target = np.where(newsgroups_train.target == 0, 0, 1)\n",
        "graphics_target = np.where(newsgroups_train.target == 1, 0, 1)\n",
        "space_target = np.where(newsgroups_train.target == 2, 0, 1)\n",
        "religion_target = np.where(newsgroups_train.target == 3, 0, 1)"
      ],
      "metadata": {
        "id": "ZYftw-op0wZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Most Important Words for Each Category based on Mutual Information"
      ],
      "metadata": {
        "id": "r0S_bReiZOsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mutual_info = mutual_info_classif(vectors, atheism_target)\n",
        "mscores = zip(vectorizer.get_feature_names_out(), mutual_info)\n",
        "print(\"Most Important Atheism Words\")\n",
        "atheism_words = sorted(mscores, key=lambda x:x[1], reverse=True)\n",
        "for i in range(10):\n",
        "  print(atheism_words[i])\n",
        "atheism_just_words = []\n",
        "atheism_mut_scores = []\n",
        "for word in atheism_words[:10]:\n",
        "  atheism_just_words.append(word[0])\n",
        "  atheism_mut_scores.append(word[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMshRexb23xc",
        "outputId": "eb8e8ee2-9b1a-4fb3-ed8f-b1e1aaece168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Important Atheism Words\n",
            "('atheism', 0.032849840393006896)\n",
            "('atheists', 0.026529748119225833)\n",
            "('space', 0.024419661344439438)\n",
            "('god', 0.0236410999751186)\n",
            "('atheist', 0.02350049683641196)\n",
            "('islam', 0.019920077487457846)\n",
            "('bobby', 0.01898624552666018)\n",
            "('graphics', 0.018582636095275953)\n",
            "('program', 0.01838553353480459)\n",
            "('religion', 0.01834529868962823)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mutual_info = mutual_info_classif(vectors, graphics_target)\n",
        "mscores = zip(vectorizer.get_feature_names_out(), mutual_info)\n",
        "print(\"Most Important Graphics Words\")\n",
        "graphics_words = sorted(mscores, key=lambda x:x[1], reverse=True)\n",
        "for i in range(10):\n",
        "  print(graphics_words[i])\n",
        "graphics_just_words = []\n",
        "graphics_mut_scores = []\n",
        "for word in graphics_words[:10]:\n",
        "  graphics_just_words.append(word[0])\n",
        "  graphics_mut_scores.append(word[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9ZH97Zh3C68",
        "outputId": "eab94f4d-47ac-4460-80a9-00911dc62a58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Important Graphics Words\n",
            "('graphics', 0.078735449451137)\n",
            "('thanks', 0.039237866280565165)\n",
            "('file', 0.034024513710758646)\n",
            "('hi', 0.032785155129032184)\n",
            "('people', 0.032419921330152784)\n",
            "('3d', 0.031090902377104136)\n",
            "('files', 0.030094343392118736)\n",
            "('god', 0.029495102939665285)\n",
            "('windows', 0.028150002661353403)\n",
            "('image', 0.0278426860435506)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mutual_info = mutual_info_classif(vectors, space_target)\n",
        "mscores = zip(vectorizer.get_feature_names_out(), mutual_info)\n",
        "print(\"Most Important Space Words\")\n",
        "space_words = sorted(mscores, key=lambda x:x[1], reverse=True)\n",
        "for i in range(10):\n",
        "  print(space_words[i])\n",
        "space_just_words = []\n",
        "space_mut_scores = []\n",
        "for word in space_words[:10]:\n",
        "  space_just_words.append(word[0])\n",
        "  space_mut_scores.append(word[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWufF25U3DYl",
        "outputId": "fdd9e263-b646-4239-c4e5-c3c1c49d5062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Important Space Words\n",
            "('space', 0.11239488227225254)\n",
            "('nasa', 0.05229455496688149)\n",
            "('orbit', 0.04765845331318783)\n",
            "('launch', 0.04201092889324566)\n",
            "('shuttle', 0.036978340064979326)\n",
            "('moon', 0.03584582368605021)\n",
            "('lunar', 0.03042444304814209)\n",
            "('spacecraft', 0.027884100207970747)\n",
            "('god', 0.0270956539791017)\n",
            "('solar', 0.02543282974861123)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mutual_info = mutual_info_classif(vectors, religion_target)\n",
        "mscores = zip(vectorizer.get_feature_names_out(), mutual_info)\n",
        "print(\"Most Important Religion Words\")\n",
        "religion_words = sorted(mscores, key=lambda x:x[1], reverse=True)\n",
        "for i in range(10):\n",
        "  print(religion_words[i])\n",
        "religion_just_words = []\n",
        "religion_mut_scores = []\n",
        "for word in religion_words[:10]:\n",
        "  religion_just_words.append(word[0])\n",
        "  religion_mut_scores.append(word[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6hENHF83EG3",
        "outputId": "1d3ebefb-f45a-4e11-c466-5e3c52191f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Important Religion Words\n",
            "('jesus', 0.03598687286090761)\n",
            "('god', 0.029977189756657953)\n",
            "('christ', 0.029892728222849895)\n",
            "('christian', 0.029817873723415027)\n",
            "('christians', 0.025354571173305862)\n",
            "('bible', 0.022509815021592213)\n",
            "('space', 0.022131912757651445)\n",
            "('children', 0.01782911470279662)\n",
            "('fbi', 0.015931068787980902)\n",
            "('koresh', 0.015705900825574822)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(word_freq.values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvjScBYn6mvu",
        "outputId": "ee7469ed-690e-447c-aa90-f5459b790051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "114977"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-compute Word Frequencies and Total Number of Words for Each Category"
      ],
      "metadata": {
        "id": "PuktcdWi9h4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cats = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
        "newsgroups_data = fetch_20newsgroups(subset='train',\n",
        "                                      remove=('headers', 'footers', 'quotes'),categories=cats)\n",
        "docs = newsgroups_data['data']\n",
        "# Preprocessing - convert docs to list of words\n",
        "docs = [[word.lower() for word in sentence.split()] for sentence in docs]\n",
        "# Create a word frequency dictionary\n",
        "word_freq = Counter([word for doc in docs for word in doc])\n",
        "all_freq = {word: freq for word, freq in word_freq.items()}\n",
        "tot_words = sum(all_freq.values())\n",
        "print(tot_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiBE2bFx9mbX",
        "outputId": "01e43637-6cac-4e85-b864-3532b9689144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "389558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ath = ['alt.atheism']\n",
        "newsgroups_data = fetch_20newsgroups(subset='train',\n",
        "                                      remove=('headers', 'footers', 'quotes'),categories=ath)\n",
        "docs = newsgroups_data['data']\n",
        "# Preprocessing - convert docs to list of words\n",
        "docs = [[word.lower() for word in sentence.split()] for sentence in docs]\n",
        "# Create a word frequency dictionary\n",
        "word_freq = Counter([word for doc in docs for word in doc])\n",
        "# Filter words that appear less than 30 times\n",
        "ath_freq = {word: freq for word, freq in word_freq.items()}\n",
        "ath_words = sum(ath_freq.values())"
      ],
      "metadata": {
        "id": "ZQ6F1BQ1810e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rel = ['talk.religion.misc']\n",
        "newsgroups_data = fetch_20newsgroups(subset='train',\n",
        "                                      remove=('headers', 'footers', 'quotes'),categories=rel)\n",
        "docs = newsgroups_data['data']\n",
        "# Preprocessing - convert docs to list of words\n",
        "docs = [[word.lower() for word in sentence.split()] for sentence in docs]\n",
        "# Create a word frequency dictionary\n",
        "word_freq = Counter([word for doc in docs for word in doc])\n",
        "# Filter words that appear less than 30 times\n",
        "rel_freq = {word: freq for word, freq in word_freq.items()}\n",
        "rel_words = sum(rel_freq.values())"
      ],
      "metadata": {
        "id": "lzG32YIM-Em7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = ['comp.graphics']\n",
        "newsgroups_data = fetch_20newsgroups(subset='train',\n",
        "                                      remove=('headers', 'footers', 'quotes'),categories=graph)\n",
        "docs = newsgroups_data['data']\n",
        "# Preprocessing - convert docs to list of words\n",
        "docs = [[word.lower() for word in sentence.split()] for sentence in docs]\n",
        "# Create a word frequency dictionary\n",
        "word_freq = Counter([word for doc in docs for word in doc])\n",
        "# Filter words that appear less than 30 times\n",
        "graph_freq = {word: freq for word, freq in word_freq.items()}\n",
        "graph_words = sum(word_freq.values())"
      ],
      "metadata": {
        "id": "T_xxyrl_-FJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spc = ['sci.space']\n",
        "newsgroups_data = fetch_20newsgroups(subset='train',\n",
        "                                      remove=('headers', 'footers', 'quotes'),categories=spc)\n",
        "docs = newsgroups_data['data']\n",
        "# Preprocessing - convert docs to list of words\n",
        "docs = [[word.lower() for word in sentence.split()] for sentence in docs]\n",
        "# Create a word frequency dictionary\n",
        "word_freq = Counter([word for doc in docs for word in doc])\n",
        "# Filter words that appear less than 30 times\n",
        "spc_freq = {word: freq for word, freq in word_freq.items()}\n",
        "spc_words = sum(spc_freq.values())"
      ],
      "metadata": {
        "id": "PGuj9_cb-Fxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Atheism"
      ],
      "metadata": {
        "id": "tdPqqQBFvBTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to deal with NoneType returns from frequency calls\n",
        "def default_to_zero(val):\n",
        "  if val == None:\n",
        "    return 0\n",
        "  else:\n",
        "    return val"
      ],
      "metadata": {
        "id": "IuWb32Oaz4a_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculate the bayes and lift for this category"
      ],
      "metadata": {
        "id": "OXPlxeNJZi1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bayes_list = []\n",
        "lifts_list = []\n",
        "for word in atheism_just_words:\n",
        "  print(\"Word: \", word)\n",
        "  # get the frequency of the word in this category\n",
        "  word_frequency = default_to_zero(ath_freq.get(word))\n",
        "  category_freq = word_frequency/ath_words\n",
        "\n",
        "  # now we add up the frequency of this word from all the other categories\n",
        "  other_frequency = default_to_zero(rel_freq.get(word)) + default_to_zero(graph_freq.get(word)) + default_to_zero(spc_freq.get(word))\n",
        "  other_num_words = rel_words + graph_words + spc_words\n",
        "  other_freq = other_frequency/other_num_words\n",
        "\n",
        "  bayes = category_freq/other_freq\n",
        "  bayes_list.append(bayes)\n",
        "  print(\"Bayes: \", bayes)\n",
        "\n",
        "  # to calculate the lift, we just add this category's frequency and num_words to the denominator\n",
        "  # so that it calculates the category frequency over the total frequency\n",
        "  other_frequency += default_to_zero(ath_freq.get(word))\n",
        "  other_num_words += ath_words\n",
        "  tot_freq = other_frequency/other_num_words\n",
        "\n",
        "  lift = category_freq/tot_freq\n",
        "  lifts_list.append(lift)\n",
        "  print(\"Lift: \", lift)\n",
        "  print(\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geeuLhmCvAWJ",
        "outputId": "c4f0f2b5-3b72-41ff-edbc-a3fd2522d4f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word:  atheism\n",
            "Bayes:  238.13273672364824\n",
            "Lift:  4.120167588469056\n",
            " \n",
            "Word:  atheists\n",
            "Bayes:  103.9846283693264\n",
            "Lift:  4.051396396128189\n",
            " \n",
            "Word:  space\n",
            "Bayes:  0.02483783433884206\n",
            "Lift:  0.0324070102689416\n",
            " \n",
            "Word:  god\n",
            "Bayes:  4.168431518067586\n",
            "Lift:  2.369925704671734\n",
            " \n",
            "Word:  atheist\n",
            "Bayes:  111.12861047103586\n",
            "Lift:  4.059128068639884\n",
            " \n",
            "Word:  islam\n",
            "Bayes:  22.622609988746582\n",
            "Lift:  3.6612443063072715\n",
            " \n",
            "Word:  bobby\n",
            "Bayes:  92.077991533144\n",
            "Lift:  4.0359330511048\n",
            " \n",
            "Word:  graphics\n",
            "Bayes:  0.0\n",
            "Lift:  0.0\n",
            " \n",
            "Word:  program\n",
            "Bayes:  0.07029748685568951\n",
            "Lift:  0.09043544742921249\n",
            " \n",
            "Word:  religion\n",
            "Bayes:  8.527419905532547\n",
            "Lift:  3.0423232301832495\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "ath_df = pd.DataFrame(data=[atheism_just_words, atheism_mut_scores, bayes_list, lifts_list], index=[\"Words\", \"Mutual Information\", \"Bayes\", \"Lifts\"]).T\n",
        "ath_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "hg2vAWvW0bKK",
        "outputId": "2676250e-02aa-456b-d1c1-e47691dfab99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Words Mutual Information       Bayes     Lifts\n",
              "0   atheism            0.03285  238.132737  4.120168\n",
              "1  atheists            0.02653  103.984628  4.051396\n",
              "2     space            0.02442    0.024838  0.032407\n",
              "3       god           0.023641    4.168432  2.369926\n",
              "4   atheist             0.0235   111.12861  4.059128\n",
              "5     islam            0.01992    22.62261  3.661244\n",
              "6     bobby           0.018986   92.077992  4.035933\n",
              "7  graphics           0.018583         0.0       0.0\n",
              "8   program           0.018386    0.070297  0.090435\n",
              "9  religion           0.018345     8.52742  3.042323"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2d447f0-984e-483a-b78e-58939d788fdc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Words</th>\n",
              "      <th>Mutual Information</th>\n",
              "      <th>Bayes</th>\n",
              "      <th>Lifts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>atheism</td>\n",
              "      <td>0.03285</td>\n",
              "      <td>238.132737</td>\n",
              "      <td>4.120168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>atheists</td>\n",
              "      <td>0.02653</td>\n",
              "      <td>103.984628</td>\n",
              "      <td>4.051396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>space</td>\n",
              "      <td>0.02442</td>\n",
              "      <td>0.024838</td>\n",
              "      <td>0.032407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>god</td>\n",
              "      <td>0.023641</td>\n",
              "      <td>4.168432</td>\n",
              "      <td>2.369926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>atheist</td>\n",
              "      <td>0.0235</td>\n",
              "      <td>111.12861</td>\n",
              "      <td>4.059128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>islam</td>\n",
              "      <td>0.01992</td>\n",
              "      <td>22.62261</td>\n",
              "      <td>3.661244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>bobby</td>\n",
              "      <td>0.018986</td>\n",
              "      <td>92.077992</td>\n",
              "      <td>4.035933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>graphics</td>\n",
              "      <td>0.018583</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>program</td>\n",
              "      <td>0.018386</td>\n",
              "      <td>0.070297</td>\n",
              "      <td>0.090435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>religion</td>\n",
              "      <td>0.018345</td>\n",
              "      <td>8.52742</td>\n",
              "      <td>3.042323</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2d447f0-984e-483a-b78e-58939d788fdc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2d447f0-984e-483a-b78e-58939d788fdc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2d447f0-984e-483a-b78e-58939d788fdc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Religion"
      ],
      "metadata": {
        "id": "oxdh8_BT1AGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bayes_list = []\n",
        "lifts_list = []\n",
        "for word in religion_just_words:\n",
        "  print(\"Word: \", word)\n",
        "  # get the frequency of the word in this category\n",
        "  word_frequency = default_to_zero(rel_freq.get(word))\n",
        "  category_freq = word_frequency/rel_words\n",
        "\n",
        "  # now we add up the frequency of this word from all the other categories\n",
        "  other_frequency = default_to_zero(ath_freq.get(word)) + default_to_zero(graph_freq.get(word)) + default_to_zero(spc_freq.get(word))\n",
        "  other_num_words = ath_words + graph_words + spc_words\n",
        "  other_freq = other_frequency/other_num_words\n",
        "\n",
        "  bayes = category_freq/other_freq\n",
        "  bayes_list.append(bayes)\n",
        "  print(\"Bayes: \", bayes)\n",
        "\n",
        "  # to calculate the lift, we just add this category's frequency and num_words to the denominator\n",
        "  # so that it calculates the category frequency over the total frequency\n",
        "  other_frequency += default_to_zero(rel_freq.get(word))\n",
        "  other_num_words += rel_words\n",
        "  tot_freq = other_frequency/other_num_words\n",
        "\n",
        "  lift = category_freq/tot_freq\n",
        "  lifts_list.append(lift)\n",
        "  print(\"Lift: \", lift)\n",
        "  print(\" \")\n",
        "\n",
        "rel_df = pd.DataFrame(data=[religion_just_words, religion_mut_scores, bayes_list, lifts_list], index=[\"Words\", \"Mutual Information\", \"Bayes\", \"Lifts\"]).T\n",
        "rel_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "StSOUT-h1Byu",
        "outputId": "4e4e4abe-df76-4d72-fbf7-cdfff5c9382d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word:  jesus\n",
            "Bayes:  6.507496278962735\n",
            "Lift:  2.9725429935292063\n",
            " \n",
            "Word:  god\n",
            "Bayes:  2.6066684047205677\n",
            "Lift:  1.93528281530835\n",
            " \n",
            "Word:  christ\n",
            "Bayes:  41.75943054152054\n",
            "Lift:  4.260754443321643\n",
            " \n",
            "Word:  christian\n",
            "Bayes:  6.289852115725919\n",
            "Lift:  2.9361550227493565\n",
            " \n",
            "Word:  christians\n",
            "Bayes:  6.536258693455389\n",
            "Lift:  2.9772352476626387\n",
            " \n",
            "Word:  bible\n",
            "Bayes:  4.5726912670264035\n",
            "Lift:  2.5813551509789\n",
            " \n",
            "Word:  space\n",
            "Bayes:  0.004703697965929324\n",
            "Lift:  0.005991274035831097\n",
            " \n",
            "Word:  children\n",
            "Bayes:  11.983140938001545\n",
            "Lift:  3.554218822791057\n",
            " \n",
            "Word:  fbi\n",
            "Bayes:  105.30639006122571\n",
            "Lift:  4.476879668707524\n",
            " \n",
            "Word:  koresh\n",
            "Bayes:  18.51939963145693\n",
            "Lift:  3.87203272646835\n",
            " \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Words Mutual Information      Bayes     Lifts\n",
              "0       jesus           0.035987   6.507496  2.972543\n",
              "1         god           0.029977   2.606668  1.935283\n",
              "2      christ           0.029893  41.759431  4.260754\n",
              "3   christian           0.029818   6.289852  2.936155\n",
              "4  christians           0.025355   6.536259  2.977235\n",
              "5       bible            0.02251   4.572691  2.581355\n",
              "6       space           0.022132   0.004704  0.005991\n",
              "7    children           0.017829  11.983141  3.554219\n",
              "8         fbi           0.015931  105.30639   4.47688\n",
              "9      koresh           0.015706    18.5194  3.872033"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09cba406-4c6f-4461-bec5-403b9c4e811a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Words</th>\n",
              "      <th>Mutual Information</th>\n",
              "      <th>Bayes</th>\n",
              "      <th>Lifts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jesus</td>\n",
              "      <td>0.035987</td>\n",
              "      <td>6.507496</td>\n",
              "      <td>2.972543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>god</td>\n",
              "      <td>0.029977</td>\n",
              "      <td>2.606668</td>\n",
              "      <td>1.935283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>christ</td>\n",
              "      <td>0.029893</td>\n",
              "      <td>41.759431</td>\n",
              "      <td>4.260754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>christian</td>\n",
              "      <td>0.029818</td>\n",
              "      <td>6.289852</td>\n",
              "      <td>2.936155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>christians</td>\n",
              "      <td>0.025355</td>\n",
              "      <td>6.536259</td>\n",
              "      <td>2.977235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>bible</td>\n",
              "      <td>0.02251</td>\n",
              "      <td>4.572691</td>\n",
              "      <td>2.581355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>space</td>\n",
              "      <td>0.022132</td>\n",
              "      <td>0.004704</td>\n",
              "      <td>0.005991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>children</td>\n",
              "      <td>0.017829</td>\n",
              "      <td>11.983141</td>\n",
              "      <td>3.554219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>fbi</td>\n",
              "      <td>0.015931</td>\n",
              "      <td>105.30639</td>\n",
              "      <td>4.47688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>koresh</td>\n",
              "      <td>0.015706</td>\n",
              "      <td>18.5194</td>\n",
              "      <td>3.872033</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09cba406-4c6f-4461-bec5-403b9c4e811a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09cba406-4c6f-4461-bec5-403b9c4e811a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09cba406-4c6f-4461-bec5-403b9c4e811a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graphics"
      ],
      "metadata": {
        "id": "_YQsF6iU1cKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bayes_list = []\n",
        "lifts_list = []\n",
        "for word in graphics_just_words:\n",
        "  print(\"Word: \", word)\n",
        "  # get the frequency of the word in this category\n",
        "  word_frequency = default_to_zero(graph_freq.get(word))\n",
        "  category_freq = word_frequency/graph_words\n",
        "\n",
        "  # now we add up the frequency of this word from all the other categories\n",
        "  other_frequency = default_to_zero(ath_freq.get(word)) + default_to_zero(rel_freq.get(word)) + default_to_zero(spc_freq.get(word))\n",
        "  other_num_words = ath_words + rel_words + spc_words\n",
        "  other_freq = other_frequency/other_num_words\n",
        "\n",
        "  bayes = category_freq/other_freq\n",
        "  bayes_list.append(bayes)\n",
        "  print(\"Bayes: \", bayes)\n",
        "\n",
        "  # to calculate the lift, we just add this category's frequency and num_words to the denominator\n",
        "  # so that it calculates the category frequency over the total frequency\n",
        "  other_frequency += default_to_zero(graph_freq.get(word))\n",
        "  other_num_words += graph_words\n",
        "  tot_freq = other_frequency/other_num_words\n",
        "\n",
        "  lift = category_freq/tot_freq\n",
        "  lifts_list.append(lift)\n",
        "  print(\"Lift: \", lift)\n",
        "  print(\" \")\n",
        "\n",
        "graph_df = pd.DataFrame(data=[graphics_just_words, graphics_mut_scores, bayes_list, lifts_list], index=[\"Words\", \"Mutual Information\", \"Bayes\", \"Lifts\"]).T\n",
        "graph_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jXaBYIYd1bY0",
        "outputId": "b0e5e60f-45f2-44b1-da95-550a40bf33e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word:  graphics\n",
            "Bayes:  354.9520957434111\n",
            "Lift:  4.188757619310011\n",
            " \n",
            "Word:  thanks\n",
            "Bayes:  6.603759920807649\n",
            "Lift:  2.8394021114101444\n",
            " \n",
            "Word:  file\n",
            "Bayes:  41.34385206102232\n",
            "Lift:  3.920821868671299\n",
            " \n",
            "Word:  hi\n",
            "Bayes:  19.361023404186064\n",
            "Lift:  3.6230033434551516\n",
            " \n",
            "Word:  people\n",
            "Bayes:  0.2737284439961053\n",
            "Lift:  0.33051960326257523\n",
            " \n",
            "Word:  3d\n",
            "Bayes:  193.61023404186062\n",
            "Lift:  4.157544820358371\n",
            " \n",
            "Word:  files\n",
            "Bayes:  14.687672927313564\n",
            "Lift:  3.4654814589571017\n",
            " \n",
            "Word:  god\n",
            "Bayes:  0.0235535564527811\n",
            "Lift:  0.030629255319065296\n",
            " \n",
            "Word:  windows\n",
            "Bayes:  72.60383776569773\n",
            "Lift:  4.046971819816925\n",
            " \n",
            "Word:  image\n",
            "Bayes:  29.56683419088879\n",
            "Lift:  3.810924188119492\n",
            " \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Words Mutual Information       Bayes     Lifts\n",
              "0  graphics           0.078735  354.952096  4.188758\n",
              "1    thanks           0.039238     6.60376  2.839402\n",
              "2      file           0.034025   41.343852  3.920822\n",
              "3        hi           0.032785   19.361023  3.623003\n",
              "4    people            0.03242    0.273728   0.33052\n",
              "5        3d           0.031091  193.610234  4.157545\n",
              "6     files           0.030094   14.687673  3.465481\n",
              "7       god           0.029495    0.023554  0.030629\n",
              "8   windows            0.02815   72.603838  4.046972\n",
              "9     image           0.027843   29.566834  3.810924"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22c60cca-b22d-4b0f-9274-b397197e8e0d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Words</th>\n",
              "      <th>Mutual Information</th>\n",
              "      <th>Bayes</th>\n",
              "      <th>Lifts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>graphics</td>\n",
              "      <td>0.078735</td>\n",
              "      <td>354.952096</td>\n",
              "      <td>4.188758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>thanks</td>\n",
              "      <td>0.039238</td>\n",
              "      <td>6.60376</td>\n",
              "      <td>2.839402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>file</td>\n",
              "      <td>0.034025</td>\n",
              "      <td>41.343852</td>\n",
              "      <td>3.920822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hi</td>\n",
              "      <td>0.032785</td>\n",
              "      <td>19.361023</td>\n",
              "      <td>3.623003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>people</td>\n",
              "      <td>0.03242</td>\n",
              "      <td>0.273728</td>\n",
              "      <td>0.33052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3d</td>\n",
              "      <td>0.031091</td>\n",
              "      <td>193.610234</td>\n",
              "      <td>4.157545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>files</td>\n",
              "      <td>0.030094</td>\n",
              "      <td>14.687673</td>\n",
              "      <td>3.465481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>god</td>\n",
              "      <td>0.029495</td>\n",
              "      <td>0.023554</td>\n",
              "      <td>0.030629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>windows</td>\n",
              "      <td>0.02815</td>\n",
              "      <td>72.603838</td>\n",
              "      <td>4.046972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>image</td>\n",
              "      <td>0.027843</td>\n",
              "      <td>29.566834</td>\n",
              "      <td>3.810924</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22c60cca-b22d-4b0f-9274-b397197e8e0d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22c60cca-b22d-4b0f-9274-b397197e8e0d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22c60cca-b22d-4b0f-9274-b397197e8e0d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Space"
      ],
      "metadata": {
        "id": "AmAeJVtU2KJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bayes_list = []\n",
        "lifts_list = []\n",
        "for word in space_just_words:\n",
        "  print(\"Word: \", word)\n",
        "  # get the frequency of the word in this category\n",
        "  word_frequency = default_to_zero(spc_freq.get(word))\n",
        "  category_freq = word_frequency/spc_words\n",
        "\n",
        "  # now we add up the frequency of this word from all the other categories\n",
        "  other_frequency = default_to_zero(ath_freq.get(word)) + default_to_zero(rel_freq.get(word)) + default_to_zero(graph_freq.get(word))\n",
        "  other_num_words = ath_words + rel_words + graph_words\n",
        "  other_freq = other_frequency/other_num_words\n",
        "  \n",
        "  # deal with situations where word has zero frequency in other categories\n",
        "  if other_freq == 0:\n",
        "    other_freq = .001\n",
        "\n",
        "  bayes = category_freq/other_freq\n",
        "  bayes_list.append(bayes)\n",
        "  print(\"Bayes: \", bayes)\n",
        "\n",
        "  # to calculate the lift, we just add this category's frequency and num_words to the denominator\n",
        "  # so that it calculates the category frequency over the total frequency\n",
        "  other_frequency += default_to_zero(spc_freq.get(word))\n",
        "  other_num_words += spc_words\n",
        "  tot_freq = other_frequency/other_num_words\n",
        "\n",
        "  lift = category_freq/tot_freq\n",
        "  lifts_list.append(lift)\n",
        "  print(\"Lift: \", lift)\n",
        "  print(\" \")\n",
        "\n",
        "spc_df = pd.DataFrame(data=[space_just_words, space_mut_scores, bayes_list, lifts_list], index=[\"Words\", \"Mutual Information\", \"Bayes\", \"Lifts\"]).T\n",
        "spc_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rL1PDBmH2LtE",
        "outputId": "f7be058d-f71f-4de6-f855-6be628852e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word:  space\n",
            "Bayes:  43.4615775216328\n",
            "Lift:  3.087373797958662\n",
            " \n",
            "Word:  nasa\n",
            "Bayes:  34.30409501979579\n",
            "Lift:  3.0473828905612166\n",
            " \n",
            "Word:  orbit\n",
            "Bayes:  61.79231089810377\n",
            "Lift:  3.133063540284343\n",
            " \n",
            "Word:  launch\n",
            "Bayes:  128.6403563242342\n",
            "Lift:  3.1912507523473685\n",
            " \n",
            "Word:  shuttle\n",
            "Bayes:  84.82399041466972\n",
            "Lift:  3.163199752636638\n",
            " \n",
            "Word:  moon\n",
            "Bayes:  69.65678683058971\n",
            "Lift:  3.1455245884559284\n",
            " \n",
            "Word:  lunar\n",
            "Bayes:  1.4086267972494269\n",
            "Lift:  3.24699312356741\n",
            " \n",
            "Word:  spacecraft\n",
            "Bayes:  0.758491352365076\n",
            "Lift:  3.24699312356741\n",
            " \n",
            "Word:  god\n",
            "Bayes:  0.016401409661075984\n",
            "Lift:  0.02352893567802471\n",
            " \n",
            "Word:  solar\n",
            "Bayes:  215.71133986247133\n",
            "Lift:  3.2135189676543434\n",
            " \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Words Mutual Information       Bayes     Lifts\n",
              "0       space           0.112395   43.461578  3.087374\n",
              "1        nasa           0.052295   34.304095  3.047383\n",
              "2       orbit           0.047658   61.792311  3.133064\n",
              "3      launch           0.042011  128.640356  3.191251\n",
              "4     shuttle           0.036978    84.82399    3.1632\n",
              "5        moon           0.035846   69.656787  3.145525\n",
              "6       lunar           0.030424    1.408627  3.246993\n",
              "7  spacecraft           0.027884    0.758491  3.246993\n",
              "8         god           0.027096    0.016401  0.023529\n",
              "9       solar           0.025433   215.71134  3.213519"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-308cfd21-ee0a-4eae-b1fd-6f48326ea57c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Words</th>\n",
              "      <th>Mutual Information</th>\n",
              "      <th>Bayes</th>\n",
              "      <th>Lifts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>space</td>\n",
              "      <td>0.112395</td>\n",
              "      <td>43.461578</td>\n",
              "      <td>3.087374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nasa</td>\n",
              "      <td>0.052295</td>\n",
              "      <td>34.304095</td>\n",
              "      <td>3.047383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>orbit</td>\n",
              "      <td>0.047658</td>\n",
              "      <td>61.792311</td>\n",
              "      <td>3.133064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>launch</td>\n",
              "      <td>0.042011</td>\n",
              "      <td>128.640356</td>\n",
              "      <td>3.191251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shuttle</td>\n",
              "      <td>0.036978</td>\n",
              "      <td>84.82399</td>\n",
              "      <td>3.1632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>moon</td>\n",
              "      <td>0.035846</td>\n",
              "      <td>69.656787</td>\n",
              "      <td>3.145525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lunar</td>\n",
              "      <td>0.030424</td>\n",
              "      <td>1.408627</td>\n",
              "      <td>3.246993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>spacecraft</td>\n",
              "      <td>0.027884</td>\n",
              "      <td>0.758491</td>\n",
              "      <td>3.246993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>god</td>\n",
              "      <td>0.027096</td>\n",
              "      <td>0.016401</td>\n",
              "      <td>0.023529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>solar</td>\n",
              "      <td>0.025433</td>\n",
              "      <td>215.71134</td>\n",
              "      <td>3.213519</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-308cfd21-ee0a-4eae-b1fd-6f48326ea57c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-308cfd21-ee0a-4eae-b1fd-6f48326ea57c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-308cfd21-ee0a-4eae-b1fd-6f48326ea57c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2-Gram PMI"
      ],
      "metadata": {
        "id": "hFDfvMZ5Z6Ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cats = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
        "newsgroups_data = fetch_20newsgroups(subset='train',\n",
        "                                      remove=('headers', 'footers', 'quotes'),categories=cats)"
      ],
      "metadata": {
        "id": "LswF7DTsaVvX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = newsgroups_data['data']\n",
        "\n",
        "# Preprocessing - convert docs to list of words\n",
        "docs = [[word.lower() for word in sentence.split() if word not in stop_words] for sentence in docs]\n",
        "\n",
        "# Create a word frequency dictionary\n",
        "word_freq = Counter([word for doc in docs for word in doc])\n",
        "\n",
        "# Filter words that appear less than 10 times\n",
        "word_freq = {word: freq for word, freq in word_freq.items() if freq >= 30}\n",
        "\n",
        "# Calculate number of docs\n",
        "N = len(docs)\n",
        "\n",
        "# Create a set of words to store words that have already been processed\n",
        "processed_words = set()"
      ],
      "metadata": {
        "id": "NiVm-L2KZ5uo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we want to use PMI to calculate the most correlated words to the following given word list"
      ],
      "metadata": {
        "id": "pfbQTEdHaIX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['space', 'god', 'time', 'good', 'long', 'use', 'point', 'program', 'nasa', 'software', 'shuttle', 'moon', 'launch', 'data', 'orbit', 'lunar', 'graphics', 'software', 'image', 'earth', 'program', 'computer', 'christian']"
      ],
      "metadata": {
        "id": "r7Fkbb7ZZqSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate PMI for each word-word pair\n",
        "\n",
        "pmi_dict = {}\n",
        "for i, doc1 in enumerate(docs):\n",
        "    for w1 in set(doc1) & set(words):\n",
        "        if w1 in processed_words:\n",
        "            continue\n",
        "        processed_words.add(w1)\n",
        "        p_w1 = word_freq[w1] / N\n",
        "        for j, doc2 in enumerate(docs):\n",
        "            for w2 in set(doc2) & set(word_freq.keys()):\n",
        "                if w2 in processed_words or w1 == w2:\n",
        "                    continue\n",
        "                key = (w1, w2)\n",
        "                if key in pmi_dict:\n",
        "                    continue\n",
        "                p_w2 = word_freq[w2] / N\n",
        "                p_w1_w2 = len([d for d in docs if w1 in d and w2 in d]) / N\n",
        "                pmi = np.log(p_w1_w2 / (p_w1 * p_w2))\n",
        "                pmi_dict[key] = pmi\n",
        "                pmi_dict[(w2, w1)] = pmi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xqcDEj3aNlY",
        "outputId": "4f04277a-3943-488f-8ded-8be6c9f94cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-d335e83517b7>:19: RuntimeWarning: divide by zero encountered in log\n",
            "  pmi = np.log(p_w1_w2 / (p_w1 * p_w2))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_correlated_words = 10\n",
        "for word in words:\n",
        "  correlated_words = sorted(pmi_dict.keys(), key=lambda x: pmi_dict[x], reverse=True)\n",
        "  correlated_words = [(w2, pmi_dict[(word, w2)]) for w1, w2 in correlated_words if w1 == word][:num_correlated_words]\n",
        "  print(f\"Most correlated words for '{word}': {correlated_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89Umkz9TaP9s",
        "outputId": "305ccc42-7974-4e4c-cc91-16452b1ec543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most correlated words for 'space': [('space.', 0.5620154199129188), ('orbiting', 0.3994964904151439), ('office', 0.37611604177108027), ('exploration', 0.3613447244507679), ('fuel', 0.33887186859870927), ('agency', 0.33887186859870927), ('other', 0.29631225417991336), ('systems,', 0.27433334746113797), ('release', 0.27433334746113797), ('u.s.', 0.23177373304234192)]\n",
            "Most correlated words for 'god': [(\"god's\", 0.9207253289420209), ('people,', 0.8987464222232454), ('bible,', 0.8381218004068108), ('tells', 0.7761441001309131), ('do.', 0.7570959051602186), ('lord', 0.716424865429291), ('evil', 0.7009206788933258), ('life.', 0.6980757267610944), (\"one's\", 0.6911070574450008), ('exist', 0.6890258912411765)]\n",
            "Most correlated words for 'time': [('spend', 1.1422305625380738), ('systems,', 1.1104818642234935), ('knew', 1.1104818642234935), ('present', 1.0914336692527988), ('amount', 1.0845063778202328), ('difficult', 1.083082890035379), ('responsible', 1.0797102055567398), ('eventually', 1.041488992736542), ('behind', 1.0208697055338063), ('lost', 1.0151716844191687)]\n",
            "Most correlated words for 'good': [('eventually', 1.0892535636036398), ('good.', 1.0892535636036398), ('us,', 1.085339664282503), (\"one's\", 1.0247150424660685), ('changed', 1.0247150424660685), ('apply', 1.0022421866140099), ('expect', 1.0011845450558745), ('respect', 0.9487291354881465), ('worth', 0.9446723347925322), ('earlier', 0.9294048626617437)]\n",
            "Most correlated words for 'long': [('caused', 1.4359501899376996), ('hand,', 1.3240322737337145), ('supported', 1.2668738598937659), ('plan', 1.2668738598937659), ('especially', 1.2485247212255692), ('offer', 1.2340840370707749), ('program,', 1.2340840370707749), ('them,', 1.2260518653735106), ('shows', 1.21280663862349), ('bring', 1.21280663862349)]\n",
            "Most correlated words for 'use': [('plan', 0.9023761902738242), ('years,', 0.8978410351084328), ('release', 0.8079847059865719), ('particularly', 0.7707405328142009), ('(not', 0.7547401914677598), ('short', 0.7308727100611161), ('allowed', 0.7294223834834698), ('product', 0.7082201758328668), ('30', 0.7034468970802092), ('gives', 0.6853116850359965)]\n",
            "Most correlated words for 'point': [('necessarily', 1.3230208622889061), ('accepted', 1.3134514112727553), ('regarding', 1.2806615884497643), ('point.', 1.2489128901351843), ('admit', 1.233408703599219), ('intended', 1.2201634768491982), ('red', 1.2006188807762281), ('none', 1.184618539429787), ('function', 1.1778388524444083), ('reasons', 1.1778388524444083)]\n",
            "Most correlated words for 'program': [('office', 1.1464442100339631), ('program,', 1.1247042233975573), ('program.', 1.077451338547012), ('space.', 1.0774513385470117), ('internet', 0.9952132403100399), ('screen', 0.9641226532400087), ('final', 0.9477735152384792), ('plus', 0.9477735152384792), ('systems,', 0.9211052681563178), ('top', 0.9211052681563178)]\n",
            "Most correlated words for 'nasa': [('safety', 1.6310431259965976), ('ames', 1.6258951094791962), ('exploration', 1.18903314731036), ('perfect', 1.067441436723951), ('other', 1.0219790626471938), ('press', 1.0219790626471936), ('agency', 1.0219790626471936), ('u.s.', 0.9574405415096227), ('washington,', 0.9574405415096225), ('variety', 0.9266688828428689)]\n",
            "Most correlated words for 'software': [('engineering', 1.1560510445271552), ('frame', 1.0972857353009038), ('other', 1.0610826866369432), ('digital', 1.0559675859701727), ('ibm', 0.9759248782966363), ('variety', 0.9294048626617436), ('product', 0.9294048626617436), ('advanced', 0.9203550271418258), ('plus', 0.9203550271418258), ('directly', 0.9130110528860671)]\n",
            "Most correlated words for 'shuttle': [('exploration', 1.6427762556843153), ('office', 1.5447150425081004), ('fuel', 1.4757221710211488), ('solid', 1.350559028067143), ('resources', 1.3375718325403316), ('elements', 1.3058231342257514), ('facility', 1.3058231342257514), ('service', 1.2891362154407369), ('return', 1.2525786197069393), ('other', 1.2525786197069393)]\n",
            "Most correlated words for 'moon': [('base', 1.601159056228981), ('plan', 1.5028139727295022), ('spend', 1.228862093089623), ('billion', 1.2208299213923588), ('saturn', 1.207584694642338), ('larger', 1.1971133947750427), ('orbiting', 1.0385083645984043), ('space,', 1.0385083645984043), ('fuel', 1.0385083645984043), ('went', 1.0165294578796291)]\n",
            "Most correlated words for 'launch': [('exploration', 1.068108834374695), ('atmosphere', 1.0681088343746947), ('orbit.', 0.9771370561689684), ('agency', 0.9627483187168687), ('saturn', 0.9270302361147895), ('payload', 0.9270302361147895), ('delta', 0.8674381389125438), ('space.', 0.8449652830604852), ('orbiting', 0.8449652830604852), ('titan', 0.8449652830604852)]\n",
            "Most correlated words for 'data': [('data,', 1.008915852029698), ('particularly', 0.8936498073824684), ('advanced', 0.8598199428640636), ('global', 0.846396922531923), ('distributed', 0.772288950378201), ('elements', 0.6948470244047219), ('release', 0.6948470244047219), ('top', 0.6900508521412289), ('range', 0.6881729173170288), ('space.', 0.6640753657379683)]\n",
            "Most correlated words for 'orbit': [('orbiting', 1.878259019350225), ('fuel', 1.878259019350225), ('delta', 1.7829488395459), ('orbit.', 1.6919770613401734), ('planet', 1.6876386597415751), ('saturn', 1.6418702412859947), ('propulsion', 1.5753094747676555), ('30', 1.5598052882316906), ('other', 1.5598052882316906), ('gravity', 1.5234376440608153)]\n",
            "Most correlated words for 'lunar': [('exploration', 1.5563026576804881), ('fuel', 1.484558752821647), ('gravity', 1.3304080729943886), ('orbiting', 1.2838880573594957), ('15', 1.222194488354156), ('plan', 1.188577877555171), ('global', 1.1661050217031126), ('low', 1.0474992792952653), ('space.', 1.0325736290785898), ('u.s.', 1.0145551235759114)]\n",
            "Most correlated words for 'graphics': [('programming', 1.116469906068116), ('newsgroup', 1.002059554890372), ('shareware', 0.9783195675872989), ('card', 0.9341483492741616), ('vga', 0.9341483492741616), ('routines', 0.915799210605965), ('fast', 0.8933263547539063), ('handle', 0.8859462474562837), ('interface', 0.851777351841034), ('j.', 0.7597949621293839)]\n",
            "Most correlated words for 'software': [('engineering', 1.1560510445271552), ('frame', 1.0972857353009038), ('other', 1.0610826866369432), ('digital', 1.0559675859701727), ('ibm', 0.9759248782966363), ('variety', 0.9294048626617436), ('product', 0.9294048626617436), ('advanced', 0.9203550271418258), ('plus', 0.9203550271418258), ('directly', 0.9130110528860671)]\n",
            "Most correlated words for 'image': [('images,', 0.46738496981150174), ('other', 0.43921409284480534), ('function', 0.41181511865669107), ('is:', 0.4064242700218145), ('particularly', 0.4064242700218145), ('digital', 0.3651061206910836), ('screen', 0.3651061206910836), ('variety', 0.34390391304048057), ('global', 0.3338535771869791), ('program,', 0.3010637543639883)]\n",
            "Most correlated words for 'earth': [('orbiting', 1.7993737192133004), ('north', 1.5582116623964124), ('offer', 1.5254218395734214), ('materials', 1.4330485194424065), ('basic', 1.4265338384212125), ('saturn', 1.4088342613218117), ('elements', 1.3983629614545163), ('planet', 1.3675913027877626), ('beyond', 1.3652630130281715), ('c.', 1.3575409669342613)]\n",
            "Most correlated words for 'program': [('office', 1.1464442100339631), ('program,', 1.1247042233975573), ('program.', 1.077451338547012), ('space.', 1.0774513385470117), ('internet', 0.9952132403100399), ('screen', 0.9641226532400087), ('final', 0.9477735152384792), ('plus', 0.9477735152384792), ('systems,', 0.9211052681563178), ('top', 0.9211052681563178)]\n",
            "Most correlated words for 'computer': [('performance', 1.629424922509451), ('electronic', 1.5424135455198213), ('j.', 1.5424135455198211), ('product', 1.4471033657154964), ('program,', 1.404263207039004), ('digital', 1.3882628656925626), ('images,', 1.3882628656925626), ('(not', 1.3600919887258665), ('price', 1.332693014537752), ('advanced', 1.332693014537752)]\n",
            "Most correlated words for 'christian': [('reasons', 1.4613103923598456), ('christianity', 1.2810700017697154), ('refer', 1.2655658152337503), ('followers', 1.2655658152337503), ('hand,', 1.2581857079361278), ('ones', 1.2581857079361278), ('people,', 1.2523205884837296), ('christ', 1.2402480072494602), ('authority', 1.2327759924107593), ('\"what', 1.2327759924107593)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance"
      ],
      "metadata": {
        "id": "qr843y-qZc7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, for the performance (measured by f1 score) graphed relative to the number of features, see my previous homework: see my previous homework here: https://github.com/EzraMW/ML/blob/main/Ezra_Wildes_20_newsgroups.ipynb. \n",
        "\n",
        "See my comments there that stemming, removing capital letters didn't help the performance of the Multinomial Bayes model. Also, neither did stripping accent charachters or making the data binary. \n",
        "\n",
        "Lastly, using a Random Forrest model made it perform significantly worse."
      ],
      "metadata": {
        "id": "YMU1EZ3gZejC"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}