{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EzraMW/ML/blob/main/Transfer_Learning_for_Newsgroups.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsRmnL7YMQVj"
      },
      "source": [
        "# Using pre-trained word embeddings\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2020/05/05<br>\n",
        "**Last modified:** 2020/05/05<br>\n",
        "**Description:** Text classification on the Newsgroup20 dataset using pre-trained GloVe word embeddings.\n",
        "\n",
        "Taken from: \n",
        "https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
        "\n",
        "Modified by Avi Rosenfeld on 2023/21/02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pswv05DTMQVm"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EJ92xh22MQVm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization, Embedding\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "MxADANtWuFJw"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pf-KpZZJMQVq"
      },
      "outputs": [],
      "source": [
        "glove_model = api.load(\"glove-wiki-gigaword-200\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM97t1vaMQVn"
      },
      "source": [
        "## Download the Newsgroup20 data\n",
        "\n",
        "Note that as opposed to our previous notebook, here we download the entire 20_newsgroup data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kQJ62LMaMQVn"
      },
      "outputs": [],
      "source": [
        "newsgroups_all = fetch_20newsgroups(subset='all', shuffle=True, random_state=42, remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_all_headers = fetch_20newsgroups(subset='all', shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transfer_learning(model, d, size, stop_words=None, words=None):\n",
        "  embedding_dim = model.vector_size \n",
        "  print(\"Embedding Dimension: \", embedding_dim)\n",
        "\n",
        "  samples = d.data\n",
        "  labels =  d.target\n",
        "  class_names = d.target_names\n",
        "\n",
        "  seed = 1337\n",
        "  rng = np.random.RandomState(seed)\n",
        "  rng.shuffle(samples)\n",
        "  rng = np.random.RandomState(seed)\n",
        "  rng.shuffle(labels)\n",
        "\n",
        "  # Extract a training & validation split\n",
        "  validation_split = 0.2\n",
        "  num_validation_samples = int(validation_split * len(samples))\n",
        "  train_samples = samples[:-num_validation_samples]\n",
        "  val_samples = samples[-num_validation_samples:]\n",
        "  train_labels = labels[:-num_validation_samples]\n",
        "  val_labels = labels[-num_validation_samples:]\n",
        "\n",
        "  vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=size)\n",
        "  text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
        "  vectorizer.adapt(text_ds)\n",
        "\n",
        "  voc = vectorizer.get_vocabulary()\n",
        "  \n",
        "  # if inputted just use these specific words for the vocabulary\n",
        "  if words != None:\n",
        "    voc = words\n",
        "\n",
        "  word_index = dict(zip(voc, range(len(voc))))\n",
        "\n",
        "  vocab_size = len(word_index)\n",
        "  num_tokens = len(voc) + 2\n",
        "  embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "\n",
        "  hits = 0\n",
        "  misses = 0\n",
        "          \n",
        "  # Prepare embedding matrix\n",
        "  if stop_words == None:\n",
        "    for word, i in word_index.items():\n",
        "        if word in model:\n",
        "          hits += 1\n",
        "          embedding_matrix[i] = model[word]\n",
        "        else:\n",
        "            misses += 1\n",
        "  else:\n",
        "    for word, i in word_index.items():\n",
        "        if word in model and word not in stop_words:\n",
        "          hits += 1\n",
        "          embedding_matrix[i] = model[word]\n",
        "        else:\n",
        "            misses += 1\n",
        "  print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
        "\n",
        "  embedding_layer = Embedding(\n",
        "      num_tokens,\n",
        "      embedding_dim,\n",
        "      embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "      trainable=False,\n",
        "  ) \n",
        "\n",
        "  int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "  embedded_sequences = embedding_layer(int_sequences_input)\n",
        "  x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
        "  x = layers.MaxPooling1D(5)(x)\n",
        "  x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "  x = layers.MaxPooling1D(5)(x)\n",
        "  x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "  x = layers.GlobalMaxPooling1D()(x)\n",
        "  x = layers.Dense(128, activation=\"relu\")(x)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
        "  model = keras.Model(int_sequences_input, preds)\n",
        "  # print(model.summary())\n",
        "\n",
        "  x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
        "  x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
        "\n",
        "  y_train = np.array(train_labels)\n",
        "  y_val = np.array(val_labels)\n",
        "\n",
        "  model.compile(\n",
        "      loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"],\n",
        "  )\n",
        "  print(\"Running Model:\")\n",
        "  model.fit(x_train, y_train, batch_size=128, epochs=30, validation_data=(x_val, y_val))\n",
        "\n",
        "  string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "  x = vectorizer(string_input)\n",
        "  preds = model(x)\n",
        "  end_to_end_model = keras.Model(string_input, preds)\n",
        "  return end_to_end_model"
      ],
      "metadata": {
        "id": "EJGbGiepjERZ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without Headers, Footers, and Quotes"
      ],
      "metadata": {
        "id": "DFTXGxSelF2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_learning(glove_model, newsgroups_all_headers, 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt1e86fclIao",
        "outputId": "fe44c65e-472d-4d2d-9864-b0522caaaeb8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Dimension:  200\n",
            "Converted 17655 words (2345 misses)\n",
            "Running Model:\n",
            "Epoch 1/30\n",
            "118/118 [==============================] - 14s 18ms/step - loss: 2.6302 - acc: 0.1478 - val_loss: 1.9788 - val_acc: 0.2966\n",
            "Epoch 2/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 1.7372 - acc: 0.3976 - val_loss: 1.1859 - val_acc: 0.6007\n",
            "Epoch 3/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 1.1511 - acc: 0.6100 - val_loss: 0.9612 - val_acc: 0.6702\n",
            "Epoch 4/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.8237 - acc: 0.7153 - val_loss: 0.7552 - val_acc: 0.7437\n",
            "Epoch 5/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.6000 - acc: 0.7920 - val_loss: 0.6881 - val_acc: 0.7623\n",
            "Epoch 6/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.4466 - acc: 0.8476 - val_loss: 0.6523 - val_acc: 0.8023\n",
            "Epoch 7/30\n",
            "118/118 [==============================] - 2s 15ms/step - loss: 0.3214 - acc: 0.8947 - val_loss: 0.6186 - val_acc: 0.8106\n",
            "Epoch 8/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.2272 - acc: 0.9282 - val_loss: 0.6456 - val_acc: 0.8236\n",
            "Epoch 9/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.1736 - acc: 0.9446 - val_loss: 0.7146 - val_acc: 0.8198\n",
            "Epoch 10/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.1103 - acc: 0.9649 - val_loss: 0.7095 - val_acc: 0.8408\n",
            "Epoch 11/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.0906 - acc: 0.9715 - val_loss: 0.8184 - val_acc: 0.8206\n",
            "Epoch 12/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.0714 - acc: 0.9795 - val_loss: 0.7832 - val_acc: 0.8382\n",
            "Epoch 13/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.0503 - acc: 0.9846 - val_loss: 0.8531 - val_acc: 0.8281\n",
            "Epoch 14/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.0513 - acc: 0.9840 - val_loss: 0.7990 - val_acc: 0.8366\n",
            "Epoch 15/30\n",
            "118/118 [==============================] - 2s 15ms/step - loss: 0.0592 - acc: 0.9818 - val_loss: 0.8059 - val_acc: 0.8437\n",
            "Epoch 16/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.0732 - acc: 0.9771 - val_loss: 0.7882 - val_acc: 0.8321\n",
            "Epoch 17/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.0380 - acc: 0.9891 - val_loss: 0.9275 - val_acc: 0.8400\n",
            "Epoch 18/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.0306 - acc: 0.9905 - val_loss: 0.9507 - val_acc: 0.8366\n",
            "Epoch 19/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.0244 - acc: 0.9931 - val_loss: 0.9527 - val_acc: 0.8366\n",
            "Epoch 20/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.0321 - acc: 0.9908 - val_loss: 1.0696 - val_acc: 0.8267\n",
            "Epoch 21/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.0381 - acc: 0.9884 - val_loss: 0.9761 - val_acc: 0.8313\n",
            "Epoch 22/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.0321 - acc: 0.9912 - val_loss: 0.9250 - val_acc: 0.8429\n",
            "Epoch 23/30\n",
            "118/118 [==============================] - 1s 13ms/step - loss: 0.0442 - acc: 0.9867 - val_loss: 0.9926 - val_acc: 0.8376\n",
            "Epoch 24/30\n",
            "118/118 [==============================] - 2s 13ms/step - loss: 0.0264 - acc: 0.9930 - val_loss: 0.9713 - val_acc: 0.8411\n",
            "Epoch 25/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.0297 - acc: 0.9921 - val_loss: 0.9456 - val_acc: 0.8504\n",
            "Epoch 26/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.0267 - acc: 0.9915 - val_loss: 0.9731 - val_acc: 0.8411\n",
            "Epoch 27/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.0265 - acc: 0.9919 - val_loss: 0.9910 - val_acc: 0.8443\n",
            "Epoch 28/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.0241 - acc: 0.9933 - val_loss: 1.0531 - val_acc: 0.8302\n",
            "Epoch 29/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.0221 - acc: 0.9934 - val_loss: 1.0034 - val_acc: 0.8530\n",
            "Epoch 30/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.0373 - acc: 0.9899 - val_loss: 0.9046 - val_acc: 0.8411\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7fa0942a6d60>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model did very well with the headers etc. removed. It got a training accuracy of ~ 99% and a validation accuracy around 85%."
      ],
      "metadata": {
        "id": "Y_2KFSrllngL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With Headers, Footers, and Quotes"
      ],
      "metadata": {
        "id": "A83_Xu8clRgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_learning(glove_model, newsgroups_all, 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRst_1-olSx6",
        "outputId": "6de65fc0-a3bd-49a8-c219-d34ca30d2e1b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Dimension:  200\n",
            "Converted 18326 words (1674 misses)\n",
            "Running Model:\n",
            "Epoch 1/30\n",
            "118/118 [==============================] - 15s 20ms/step - loss: 2.7186 - acc: 0.1244 - val_loss: 2.1701 - val_acc: 0.2674\n",
            "Epoch 2/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 1.9587 - acc: 0.3299 - val_loss: 1.5963 - val_acc: 0.4585\n",
            "Epoch 3/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 1.5213 - acc: 0.4858 - val_loss: 1.4007 - val_acc: 0.5357\n",
            "Epoch 4/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 1.2890 - acc: 0.5610 - val_loss: 1.3553 - val_acc: 0.5511\n",
            "Epoch 5/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 1.1278 - acc: 0.6174 - val_loss: 1.3277 - val_acc: 0.5627\n",
            "Epoch 6/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.9781 - acc: 0.6618 - val_loss: 1.2905 - val_acc: 0.5869\n",
            "Epoch 7/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.8328 - acc: 0.7097 - val_loss: 1.3486 - val_acc: 0.5914\n",
            "Epoch 8/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.6966 - acc: 0.7585 - val_loss: 1.4513 - val_acc: 0.5885\n",
            "Epoch 9/30\n",
            "118/118 [==============================] - 2s 13ms/step - loss: 0.6040 - acc: 0.7905 - val_loss: 1.5115 - val_acc: 0.5927\n",
            "Epoch 10/30\n",
            "118/118 [==============================] - 2s 13ms/step - loss: 0.5121 - acc: 0.8242 - val_loss: 1.7328 - val_acc: 0.5890\n",
            "Epoch 11/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.4571 - acc: 0.8413 - val_loss: 1.7531 - val_acc: 0.5941\n",
            "Epoch 12/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.4064 - acc: 0.8635 - val_loss: 1.7993 - val_acc: 0.5853\n",
            "Epoch 13/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.3600 - acc: 0.8810 - val_loss: 1.8712 - val_acc: 0.6018\n",
            "Epoch 14/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.3207 - acc: 0.8935 - val_loss: 1.9358 - val_acc: 0.6004\n",
            "Epoch 15/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.2617 - acc: 0.9181 - val_loss: 2.1256 - val_acc: 0.5970\n",
            "Epoch 16/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.2466 - acc: 0.9237 - val_loss: 2.3129 - val_acc: 0.5880\n",
            "Epoch 17/30\n",
            "118/118 [==============================] - 2s 14ms/step - loss: 0.2206 - acc: 0.9317 - val_loss: 2.3142 - val_acc: 0.5925\n",
            "Epoch 18/30\n",
            "118/118 [==============================] - 2s 13ms/step - loss: 0.2054 - acc: 0.9371 - val_loss: 2.8011 - val_acc: 0.5739\n",
            "Epoch 19/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.2196 - acc: 0.9337 - val_loss: 2.5208 - val_acc: 0.6015\n",
            "Epoch 20/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.1743 - acc: 0.9463 - val_loss: 2.5764 - val_acc: 0.6063\n",
            "Epoch 21/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.1572 - acc: 0.9518 - val_loss: 2.8600 - val_acc: 0.5888\n",
            "Epoch 22/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.1657 - acc: 0.9505 - val_loss: 2.8113 - val_acc: 0.5882\n",
            "Epoch 23/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.1716 - acc: 0.9487 - val_loss: 2.7956 - val_acc: 0.5893\n",
            "Epoch 24/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.1666 - acc: 0.9511 - val_loss: 2.7990 - val_acc: 0.5914\n",
            "Epoch 25/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.1603 - acc: 0.9513 - val_loss: 2.9685 - val_acc: 0.5898\n",
            "Epoch 26/30\n",
            "118/118 [==============================] - 2s 15ms/step - loss: 0.1505 - acc: 0.9555 - val_loss: 3.0078 - val_acc: 0.5959\n",
            "Epoch 27/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.1596 - acc: 0.9530 - val_loss: 3.0805 - val_acc: 0.5980\n",
            "Epoch 28/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.1541 - acc: 0.9541 - val_loss: 3.0055 - val_acc: 0.5919\n",
            "Epoch 29/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.1503 - acc: 0.9561 - val_loss: 3.1780 - val_acc: 0.5885\n",
            "Epoch 30/30\n",
            "118/118 [==============================] - 1s 12ms/step - loss: 0.1399 - acc: 0.9574 - val_loss: 3.3334 - val_acc: 0.5811\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7fa5381cc850>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, when we left in the headers, footers and quotes the training accuracy slightly descresed (suprisingly) but the validation accuracy dramatically decreased to less than 60%. This demonstrates the tremendous amount of overfitting happening due to leaving in the headers, footers, and quotes"
      ],
      "metadata": {
        "id": "zDL5n-wBko8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, going forward, we will remove the headers, footers, and quotes from the data"
      ],
      "metadata": {
        "id": "0SxPvXNDlCCI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improve Performance for 4 Categories"
      ],
      "metadata": {
        "id": "kQBGcHALwIUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cats = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
        "# newsgroups_cats_header = fetch_20newsgroups(subset='all',categories=cats)\n",
        "newsgroups_cats = fetch_20newsgroups(subset='all',categories=cats, remove=('headers', 'footers', 'quotes'))"
      ],
      "metadata": {
        "id": "tOZ13h91hXqp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's establish the baseline metric using the glove model with these 4 categories"
      ],
      "metadata": {
        "id": "wurQRkaFqgCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_learning(glove_model, newsgroups_cats, 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWkw8gl0qLA8",
        "outputId": "b14d76f0-d554-4147-d8db-1648c6d96bc1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Dimension:  200\n",
            "Converted 15881 words (4119 misses)\n",
            "Running Model:\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 2s 27ms/step - loss: 1.3292 - acc: 0.3513 - val_loss: 1.1394 - val_acc: 0.4697\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.9427 - acc: 0.5760 - val_loss: 0.8783 - val_acc: 0.6027\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.7335 - acc: 0.6705 - val_loss: 0.6603 - val_acc: 0.6425\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.5972 - acc: 0.7207 - val_loss: 0.6617 - val_acc: 0.6987\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.5328 - acc: 0.7358 - val_loss: 0.5895 - val_acc: 0.7149\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.4577 - acc: 0.7756 - val_loss: 0.7352 - val_acc: 0.6529\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.4186 - acc: 0.8052 - val_loss: 0.6240 - val_acc: 0.7356\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.3345 - acc: 0.8432 - val_loss: 0.6669 - val_acc: 0.7386\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.2682 - acc: 0.8923 - val_loss: 0.7137 - val_acc: 0.7326\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 0.2606 - acc: 0.8819 - val_loss: 0.6417 - val_acc: 0.7386\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.2053 - acc: 0.9332 - val_loss: 0.6926 - val_acc: 0.7518\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.1293 - acc: 0.9480 - val_loss: 0.7904 - val_acc: 0.7459\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.1120 - acc: 0.9587 - val_loss: 0.7556 - val_acc: 0.7400\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.1437 - acc: 0.9380 - val_loss: 0.8292 - val_acc: 0.7548\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0868 - acc: 0.9712 - val_loss: 0.8318 - val_acc: 0.7592\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0562 - acc: 0.9797 - val_loss: 0.9654 - val_acc: 0.7563\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0503 - acc: 0.9790 - val_loss: 0.9948 - val_acc: 0.7710\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0454 - acc: 0.9804 - val_loss: 1.0251 - val_acc: 0.7607\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0455 - acc: 0.9797 - val_loss: 1.1134 - val_acc: 0.7607\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0453 - acc: 0.9797 - val_loss: 1.1436 - val_acc: 0.7725\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0438 - acc: 0.9793 - val_loss: 1.1840 - val_acc: 0.7681\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0454 - acc: 0.9790 - val_loss: 1.1571 - val_acc: 0.7548\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0445 - acc: 0.9786 - val_loss: 1.2065 - val_acc: 0.7592\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0439 - acc: 0.9779 - val_loss: 1.3124 - val_acc: 0.7489\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0467 - acc: 0.9793 - val_loss: 1.2137 - val_acc: 0.7386\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0537 - acc: 0.9760 - val_loss: 1.4631 - val_acc: 0.7430\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0474 - acc: 0.9801 - val_loss: 1.1125 - val_acc: 0.7637\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0440 - acc: 0.9793 - val_loss: 1.1205 - val_acc: 0.7622\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0431 - acc: 0.9790 - val_loss: 1.1712 - val_acc: 0.7681\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0441 - acc: 0.9779 - val_loss: 1.2625 - val_acc: 0.7548\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7fc58190c0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We acheived an over 97% training accuracy and over 75% validation accuracy. This isn't as good as we got using all 20 categories but very solid"
      ],
      "metadata": {
        "id": "Yv-8skOJqrCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try tansfering the training from different models"
      ],
      "metadata": {
        "id": "r_vHHlvGlbEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_model_300 = api.load(\"glove-wiki-gigaword-300\")"
      ],
      "metadata": {
        "id": "PstVnF3bwPEr"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_learning(glove_model_300, newsgroups_cats, 300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-KWlAHamVoL",
        "outputId": "cedafc05-690b-4910-dddd-f320fd00e145"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Dimension:  300\n",
            "Converted 16166 words (3834 misses)\n",
            "Running Model:\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 3s 41ms/step - loss: 1.3433 - acc: 0.3439 - val_loss: 1.1421 - val_acc: 0.5066\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.9240 - acc: 0.5897 - val_loss: 0.7450 - val_acc: 0.6677\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.6681 - acc: 0.6882 - val_loss: 0.6742 - val_acc: 0.6839\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.5814 - acc: 0.7085 - val_loss: 0.5839 - val_acc: 0.7297\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.4875 - acc: 0.7598 - val_loss: 0.5850 - val_acc: 0.7164\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.4117 - acc: 0.8037 - val_loss: 0.6149 - val_acc: 0.7312\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.3543 - acc: 0.8421 - val_loss: 0.6053 - val_acc: 0.7489\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.2871 - acc: 0.8756 - val_loss: 0.6735 - val_acc: 0.7282\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.2350 - acc: 0.9074 - val_loss: 0.6187 - val_acc: 0.7651\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.2142 - acc: 0.9114 - val_loss: 0.6712 - val_acc: 0.7651\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.1584 - acc: 0.9432 - val_loss: 0.7890 - val_acc: 0.7445\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.1089 - acc: 0.9657 - val_loss: 0.7845 - val_acc: 0.7814\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.0727 - acc: 0.9734 - val_loss: 1.0493 - val_acc: 0.7563\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0782 - acc: 0.9705 - val_loss: 1.0217 - val_acc: 0.7297\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.2086 - acc: 0.9221 - val_loss: 0.7263 - val_acc: 0.7651\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0927 - acc: 0.9694 - val_loss: 0.9141 - val_acc: 0.7563\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.0559 - acc: 0.9768 - val_loss: 0.9168 - val_acc: 0.7755\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.0479 - acc: 0.9786 - val_loss: 1.0248 - val_acc: 0.7814\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.0459 - acc: 0.9790 - val_loss: 1.0388 - val_acc: 0.7725\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0458 - acc: 0.9790 - val_loss: 1.0458 - val_acc: 0.7740\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0458 - acc: 0.9779 - val_loss: 1.0635 - val_acc: 0.7755\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0458 - acc: 0.9782 - val_loss: 1.0726 - val_acc: 0.7799\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0446 - acc: 0.9790 - val_loss: 1.1030 - val_acc: 0.7784\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.0576 - acc: 0.9749 - val_loss: 1.0434 - val_acc: 0.7814\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.1019 - acc: 0.9642 - val_loss: 0.9351 - val_acc: 0.7622\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.0553 - acc: 0.9779 - val_loss: 1.0301 - val_acc: 0.7533\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0498 - acc: 0.9782 - val_loss: 1.1170 - val_acc: 0.7563\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.0477 - acc: 0.9775 - val_loss: 1.1003 - val_acc: 0.7622\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0445 - acc: 0.9790 - val_loss: 1.1218 - val_acc: 0.7651\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.0444 - acc: 0.9793 - val_loss: 1.1307 - val_acc: 0.7696\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7fa45406ff10>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Very solid results but not very different than the glove model"
      ],
      "metadata": {
        "id": "3yvINcbhmfeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "id": "lj1ioyV1mcuY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_learning(w2v_model, newsgroups_cats, 300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQXbw8wHwerm",
        "outputId": "313e6965-f54a-4809-ee98-3ad6be1ac810"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Dimension:  300\n",
            "Converted 14143 words (5857 misses)\n",
            "Running Model:\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 13s 46ms/step - loss: 1.3032 - acc: 0.3572 - val_loss: 1.0284 - val_acc: 0.5569\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.8367 - acc: 0.6262 - val_loss: 0.7207 - val_acc: 0.6396\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.6783 - acc: 0.6845 - val_loss: 0.6192 - val_acc: 0.7031\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.5556 - acc: 0.7362 - val_loss: 0.5867 - val_acc: 0.7001\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.4642 - acc: 0.7731 - val_loss: 0.6013 - val_acc: 0.6765\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 1s 27ms/step - loss: 0.4117 - acc: 0.8148 - val_loss: 0.5896 - val_acc: 0.7046\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3250 - acc: 0.8594 - val_loss: 0.5969 - val_acc: 0.7061\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.2724 - acc: 0.8908 - val_loss: 0.6174 - val_acc: 0.7312\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.2015 - acc: 0.9221 - val_loss: 0.6564 - val_acc: 0.7386\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.1481 - acc: 0.9454 - val_loss: 0.6752 - val_acc: 0.7282\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.0985 - acc: 0.9679 - val_loss: 0.8880 - val_acc: 0.7149\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.1416 - acc: 0.9469 - val_loss: 0.9486 - val_acc: 0.7179\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.1109 - acc: 0.9631 - val_loss: 0.7533 - val_acc: 0.7504\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.0610 - acc: 0.9801 - val_loss: 0.8889 - val_acc: 0.7445\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0525 - acc: 0.9812 - val_loss: 0.9955 - val_acc: 0.7312\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 0s 23ms/step - loss: 0.0469 - acc: 0.9827 - val_loss: 0.8824 - val_acc: 0.7489\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.0417 - acc: 0.9834 - val_loss: 0.9857 - val_acc: 0.7489\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0408 - acc: 0.9834 - val_loss: 1.0483 - val_acc: 0.7504\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.0402 - acc: 0.9834 - val_loss: 1.0754 - val_acc: 0.7504\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0394 - acc: 0.9834 - val_loss: 1.0605 - val_acc: 0.7489\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0386 - acc: 0.9834 - val_loss: 1.0736 - val_acc: 0.7592\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.0381 - acc: 0.9834 - val_loss: 1.1362 - val_acc: 0.7489\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.0383 - acc: 0.9834 - val_loss: 1.1268 - val_acc: 0.7518\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.0403 - acc: 0.9823 - val_loss: 1.2448 - val_acc: 0.7371\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.3398 - acc: 0.9059 - val_loss: 0.9308 - val_acc: 0.6824\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.2079 - acc: 0.9306 - val_loss: 0.6290 - val_acc: 0.7371\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.0902 - acc: 0.9753 - val_loss: 0.7566 - val_acc: 0.7459\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.0456 - acc: 0.9823 - val_loss: 0.8928 - val_acc: 0.7489\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.0416 - acc: 0.9830 - val_loss: 1.0124 - val_acc: 0.7533\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0484 - acc: 0.9790 - val_loss: 0.9191 - val_acc: 0.7459\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7fc5da07b880>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This also didn't really improve on the previous model"
      ],
      "metadata": {
        "id": "YUOnViuVpw2_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Stop Words\n",
        "\n",
        "Let's try removing stop words from the dataset and see if that helps"
      ],
      "metadata": {
        "id": "AGv5hK2um1FF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
      ],
      "metadata": {
        "id": "0Bzwr6v0m6Np"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_learning(glove_model, newsgroups_cats, 200, ENGLISH_STOP_WORDS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_wR27stnsH1",
        "outputId": "981b3b5c-fd0a-4cb1-dd06-b7f3d17ce5fe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Dimension:  200\n",
            "Converted 15858 words (4142 misses)\n",
            "Running Model:\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 3s 36ms/step - loss: 1.2935 - acc: 0.3745 - val_loss: 0.9862 - val_acc: 0.6278\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.8858 - acc: 0.6185 - val_loss: 0.7313 - val_acc: 0.6455\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6763 - acc: 0.6768 - val_loss: 0.6237 - val_acc: 0.7061\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 0s 17ms/step - loss: 0.5691 - acc: 0.7162 - val_loss: 0.6188 - val_acc: 0.6987\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.4977 - acc: 0.7517 - val_loss: 0.5745 - val_acc: 0.7105\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.4277 - acc: 0.7856 - val_loss: 0.5791 - val_acc: 0.7223\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3763 - acc: 0.8133 - val_loss: 0.6253 - val_acc: 0.7134\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.3144 - acc: 0.8491 - val_loss: 0.6125 - val_acc: 0.7563\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.2917 - acc: 0.8646 - val_loss: 0.6283 - val_acc: 0.7415\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.2345 - acc: 0.9022 - val_loss: 0.7740 - val_acc: 0.7489\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.1825 - acc: 0.9351 - val_loss: 0.6959 - val_acc: 0.7578\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.1610 - acc: 0.9399 - val_loss: 0.7344 - val_acc: 0.7622\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0913 - acc: 0.9683 - val_loss: 0.8753 - val_acc: 0.7415\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0743 - acc: 0.9723 - val_loss: 0.8364 - val_acc: 0.7666\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0679 - acc: 0.9723 - val_loss: 1.2211 - val_acc: 0.7386\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0691 - acc: 0.9720 - val_loss: 0.9379 - val_acc: 0.7637\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0669 - acc: 0.9731 - val_loss: 0.9831 - val_acc: 0.7548\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0714 - acc: 0.9686 - val_loss: 0.9768 - val_acc: 0.7681\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0578 - acc: 0.9768 - val_loss: 1.2420 - val_acc: 0.7518\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.1037 - acc: 0.9609 - val_loss: 0.9035 - val_acc: 0.7740\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0839 - acc: 0.9694 - val_loss: 0.8240 - val_acc: 0.7740\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0606 - acc: 0.9731 - val_loss: 0.9085 - val_acc: 0.7784\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0565 - acc: 0.9760 - val_loss: 1.0134 - val_acc: 0.7710\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0491 - acc: 0.9779 - val_loss: 1.0433 - val_acc: 0.7681\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0475 - acc: 0.9779 - val_loss: 1.0688 - val_acc: 0.7725\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0460 - acc: 0.9786 - val_loss: 1.1051 - val_acc: 0.7799\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0455 - acc: 0.9786 - val_loss: 1.1085 - val_acc: 0.7799\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0456 - acc: 0.9771 - val_loss: 1.1576 - val_acc: 0.7814\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0457 - acc: 0.9768 - val_loss: 1.1904 - val_acc: 0.7799\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.1666 - acc: 0.9480 - val_loss: 2.1678 - val_acc: 0.6662\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7fc578165580>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other than the last epoch, which seems like an outlier, we got a training accuracy above 97% and a validation accuracy around 78%. This is slightly better than our baseline model."
      ],
      "metadata": {
        "id": "rkdhT2L3qVfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the top CHI2 Words"
      ],
      "metadata": {
        "id": "lHhTGpmRuRNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectors = vectorizer.fit_transform(newsgroups_cats.data)\n",
        "chi2score = chi2(vectors, newsgroups_cats.target)[0]\n",
        "wscores = zip(vectorizer.get_feature_names_out(),chi2score)\n",
        "wchi2 = sorted(wscores,key=lambda x:x[1],reverse = True) "
      ],
      "metadata": {
        "id": "aI9DzmHIuUjR"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chi2_words = [t[0] for t in wchi2]\n",
        "top_chi2_words = chi2_words[:5000]"
      ],
      "metadata": {
        "id": "-HSmnl71vHlD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_learning(glove_model, newsgroups_cats, 200, words=top_chi2_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRoo2Lr2wWvX",
        "outputId": "400198da-9368-44d8-9043-4deef8089051"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Dimension:  200\n",
            "Converted 4667 words (333 misses)\n",
            "Running Model:\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 3s 33ms/step - loss: 1.4144 - acc: 0.2974 - val_loss: 1.3542 - val_acc: 0.3264\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.3683 - acc: 0.3018 - val_loss: 1.3485 - val_acc: 0.3353\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 0s 18ms/step - loss: 1.3471 - acc: 0.3432 - val_loss: 1.3270 - val_acc: 0.3456\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.2911 - acc: 0.3823 - val_loss: 1.3381 - val_acc: 0.3929\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 1.2401 - acc: 0.4210 - val_loss: 1.2105 - val_acc: 0.4564\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 1.0583 - acc: 0.5391 - val_loss: 1.1264 - val_acc: 0.4727\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.8849 - acc: 0.6063 - val_loss: 1.0465 - val_acc: 0.5362\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 0s 16ms/step - loss: 0.7109 - acc: 0.6978 - val_loss: 1.4275 - val_acc: 0.4579\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.6992 - acc: 0.7052 - val_loss: 1.0591 - val_acc: 0.5303\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.5353 - acc: 0.7768 - val_loss: 1.1014 - val_acc: 0.5318\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.4563 - acc: 0.8133 - val_loss: 1.1443 - val_acc: 0.5554\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.3164 - acc: 0.8827 - val_loss: 1.2559 - val_acc: 0.5288\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.2633 - acc: 0.9066 - val_loss: 1.2405 - val_acc: 0.5687\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.1891 - acc: 0.9373 - val_loss: 1.3819 - val_acc: 0.5643\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.1239 - acc: 0.9609 - val_loss: 1.5528 - val_acc: 0.5273\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0898 - acc: 0.9694 - val_loss: 1.6260 - val_acc: 0.5554\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0717 - acc: 0.9742 - val_loss: 1.7111 - val_acc: 0.5421\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0729 - acc: 0.9708 - val_loss: 2.1337 - val_acc: 0.5421\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0677 - acc: 0.9749 - val_loss: 1.8378 - val_acc: 0.5657\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0543 - acc: 0.9779 - val_loss: 1.7765 - val_acc: 0.5716\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0499 - acc: 0.9775 - val_loss: 1.8892 - val_acc: 0.5716\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0503 - acc: 0.9771 - val_loss: 1.9634 - val_acc: 0.5968\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0470 - acc: 0.9771 - val_loss: 2.2076 - val_acc: 0.5510\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 0s 15ms/step - loss: 0.0502 - acc: 0.9760 - val_loss: 2.0168 - val_acc: 0.5643\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.4284 - acc: 0.8646 - val_loss: 1.4571 - val_acc: 0.4904\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.3230 - acc: 0.8915 - val_loss: 1.2107 - val_acc: 0.5258\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.1385 - acc: 0.9587 - val_loss: 1.5034 - val_acc: 0.5746\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0718 - acc: 0.9745 - val_loss: 1.7493 - val_acc: 0.5480\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0540 - acc: 0.9786 - val_loss: 1.8066 - val_acc: 0.5702\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0509 - acc: 0.9756 - val_loss: 1.8644 - val_acc: 0.5775\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7fc51c291250>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ouch! This significantly reduced the validation accuracy"
      ],
      "metadata": {
        "id": "AFHfWHF4wg8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_learning(w2v_model, newsgroups_cats, 300, words=top_chi2_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoLsmsJ-wpGy",
        "outputId": "07292ae5-ada2-4be4-8836-ea5d0174f884"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Dimension:  300\n",
            "Converted 4102 words (898 misses)\n",
            "Running Model:\n",
            "Epoch 1/30\n",
            "22/22 [==============================] - 2s 34ms/step - loss: 1.3850 - acc: 0.3018 - val_loss: 1.3479 - val_acc: 0.3368\n",
            "Epoch 2/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.3673 - acc: 0.2923 - val_loss: 1.3389 - val_acc: 0.3516\n",
            "Epoch 3/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.3547 - acc: 0.3221 - val_loss: 1.3289 - val_acc: 0.3530\n",
            "Epoch 4/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.3097 - acc: 0.3620 - val_loss: 1.3004 - val_acc: 0.3767\n",
            "Epoch 5/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 1.2145 - acc: 0.4328 - val_loss: 1.2025 - val_acc: 0.4461\n",
            "Epoch 6/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 1.0246 - acc: 0.5199 - val_loss: 1.3102 - val_acc: 0.3973\n",
            "Epoch 7/30\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.8586 - acc: 0.5963 - val_loss: 1.0271 - val_acc: 0.5273\n",
            "Epoch 8/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.6597 - acc: 0.7011 - val_loss: 1.4952 - val_acc: 0.3870\n",
            "Epoch 9/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.7520 - acc: 0.6561 - val_loss: 1.0242 - val_acc: 0.5790\n",
            "Epoch 10/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.5182 - acc: 0.7638 - val_loss: 1.0293 - val_acc: 0.5775\n",
            "Epoch 11/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.4564 - acc: 0.7801 - val_loss: 1.0685 - val_acc: 0.5820\n",
            "Epoch 12/30\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.3541 - acc: 0.8292 - val_loss: 1.2199 - val_acc: 0.5643\n",
            "Epoch 13/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.3306 - acc: 0.8461 - val_loss: 1.5544 - val_acc: 0.5052\n",
            "Epoch 14/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.4092 - acc: 0.8218 - val_loss: 1.2606 - val_acc: 0.5835\n",
            "Epoch 15/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.2754 - acc: 0.8926 - val_loss: 1.3536 - val_acc: 0.5879\n",
            "Epoch 16/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.1898 - acc: 0.9303 - val_loss: 1.2737 - val_acc: 0.5997\n",
            "Epoch 17/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.1265 - acc: 0.9565 - val_loss: 1.3991 - val_acc: 0.5938\n",
            "Epoch 18/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.1037 - acc: 0.9631 - val_loss: 1.4761 - val_acc: 0.6071\n",
            "Epoch 19/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.0677 - acc: 0.9749 - val_loss: 1.9068 - val_acc: 0.5761\n",
            "Epoch 20/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0744 - acc: 0.9694 - val_loss: 1.6390 - val_acc: 0.6145\n",
            "Epoch 21/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.0945 - acc: 0.9653 - val_loss: 1.6565 - val_acc: 0.6027\n",
            "Epoch 22/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0672 - acc: 0.9771 - val_loss: 1.6187 - val_acc: 0.6100\n",
            "Epoch 23/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.0536 - acc: 0.9793 - val_loss: 1.8134 - val_acc: 0.5982\n",
            "Epoch 24/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.0471 - acc: 0.9801 - val_loss: 1.8205 - val_acc: 0.6160\n",
            "Epoch 25/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.0489 - acc: 0.9786 - val_loss: 1.9346 - val_acc: 0.6219\n",
            "Epoch 26/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.0449 - acc: 0.9797 - val_loss: 1.9803 - val_acc: 0.6115\n",
            "Epoch 27/30\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.0422 - acc: 0.9815 - val_loss: 1.9797 - val_acc: 0.6100\n",
            "Epoch 28/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.0413 - acc: 0.9815 - val_loss: 2.0176 - val_acc: 0.6130\n",
            "Epoch 29/30\n",
            "22/22 [==============================] - 0s 22ms/step - loss: 0.0400 - acc: 0.9827 - val_loss: 2.0911 - val_acc: 0.6027\n",
            "Epoch 30/30\n",
            "22/22 [==============================] - 0s 21ms/step - loss: 0.0405 - acc: 0.9823 - val_loss: 2.0958 - val_acc: 0.5997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7fc47a673c70>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The word2vec model did slightly better than glove but significantly underperformed the baseline"
      ],
      "metadata": {
        "id": "0ne5pW0ew099"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Different Categories "
      ],
      "metadata": {
        "id": "qXcoIE5Dn6Rs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the suggested categories which are very different from one another\n",
        "\n",
        "Again, we will remove the headers, footers, and quotes to get the better results and better compare to previous iterations"
      ],
      "metadata": {
        "id": "ig4Nc4HtoO0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diff_cats = ['talk.religion.misc', 'comp.sys.ibm.pc.hardware', 'sci.space']\n",
        "newsgroups_diff_cats = fetch_20newsgroups(subset='all',categories=diff_cats, remove=('headers', 'footers', 'quotes'))"
      ],
      "metadata": {
        "id": "vfdnOQMyoDGD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_learning(glove_model, newsgroups_diff_cats, 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYKAAw30oh_u",
        "outputId": "eef27cc5-3f39-4f9b-bccd-62b1d93c0eb3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Dimension:  200\n",
            "Converted 15764 words (4236 misses)\n",
            "Running Model:\n",
            "Epoch 1/30\n",
            "17/17 [==============================] - 3s 48ms/step - loss: 1.0969 - acc: 0.3898 - val_loss: 1.0071 - val_acc: 0.5491\n",
            "Epoch 2/30\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.8303 - acc: 0.6121 - val_loss: 0.5460 - val_acc: 0.7842\n",
            "Epoch 3/30\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.4818 - acc: 0.8041 - val_loss: 0.3596 - val_acc: 0.8497\n",
            "Epoch 4/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.3094 - acc: 0.8758 - val_loss: 0.3016 - val_acc: 0.8844\n",
            "Epoch 5/30\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.2162 - acc: 0.9148 - val_loss: 0.3341 - val_acc: 0.8651\n",
            "Epoch 6/30\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.1765 - acc: 0.9317 - val_loss: 0.2621 - val_acc: 0.8998\n",
            "Epoch 7/30\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.1203 - acc: 0.9577 - val_loss: 0.2840 - val_acc: 0.9017\n",
            "Epoch 8/30\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.0838 - acc: 0.9663 - val_loss: 0.3563 - val_acc: 0.8844\n",
            "Epoch 9/30\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0726 - acc: 0.9692 - val_loss: 0.4180 - val_acc: 0.8825\n",
            "Epoch 10/30\n",
            "17/17 [==============================] - 1s 34ms/step - loss: 0.1353 - acc: 0.9475 - val_loss: 0.4142 - val_acc: 0.8671\n",
            "Epoch 11/30\n",
            "17/17 [==============================] - 0s 26ms/step - loss: 0.0812 - acc: 0.9678 - val_loss: 0.2782 - val_acc: 0.9037\n",
            "Epoch 12/30\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 0.0507 - acc: 0.9808 - val_loss: 0.3723 - val_acc: 0.8902\n",
            "Epoch 13/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0394 - acc: 0.9803 - val_loss: 0.3434 - val_acc: 0.9056\n",
            "Epoch 14/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0350 - acc: 0.9851 - val_loss: 0.3789 - val_acc: 0.9075\n",
            "Epoch 15/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0332 - acc: 0.9832 - val_loss: 0.4163 - val_acc: 0.9017\n",
            "Epoch 16/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0325 - acc: 0.9812 - val_loss: 0.4342 - val_acc: 0.9037\n",
            "Epoch 17/30\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0315 - acc: 0.9822 - val_loss: 0.4269 - val_acc: 0.9056\n",
            "Epoch 18/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0316 - acc: 0.9817 - val_loss: 0.4336 - val_acc: 0.9075\n",
            "Epoch 19/30\n",
            "17/17 [==============================] - 0s 23ms/step - loss: 0.0315 - acc: 0.9822 - val_loss: 0.4731 - val_acc: 0.9017\n",
            "Epoch 20/30\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.0313 - acc: 0.9817 - val_loss: 0.4552 - val_acc: 0.9056\n",
            "Epoch 21/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0305 - acc: 0.9832 - val_loss: 0.4475 - val_acc: 0.9075\n",
            "Epoch 22/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0307 - acc: 0.9832 - val_loss: 0.4787 - val_acc: 0.9056\n",
            "Epoch 23/30\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0331 - acc: 0.9822 - val_loss: 0.5360 - val_acc: 0.8844\n",
            "Epoch 24/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0334 - acc: 0.9827 - val_loss: 0.4485 - val_acc: 0.9037\n",
            "Epoch 25/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0312 - acc: 0.9832 - val_loss: 0.4820 - val_acc: 0.9017\n",
            "Epoch 26/30\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0305 - acc: 0.9832 - val_loss: 0.4586 - val_acc: 0.9056\n",
            "Epoch 27/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0304 - acc: 0.9827 - val_loss: 0.4792 - val_acc: 0.9037\n",
            "Epoch 28/30\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0304 - acc: 0.9832 - val_loss: 0.4904 - val_acc: 0.9037\n",
            "Epoch 29/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0306 - acc: 0.9832 - val_loss: 0.4854 - val_acc: 0.9037\n",
            "Epoch 30/30\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0304 - acc: 0.9832 - val_loss: 0.5192 - val_acc: 0.9017\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7fc581b66700>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WOW! These results are much better. The validation broke 90% accuracy very quickly and even the training accuracy is slightly better"
      ],
      "metadata": {
        "id": "K_T0Jzz-rJcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_learning(glove_model, newsgroups_diff_cats, 200, ENGLISH_STOP_WORDS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2BtvdzVrI0V",
        "outputId": "4f69349c-5935-485e-c31d-a6a888c6a713"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Dimension:  200\n",
            "Converted 15444 words (4556 misses)\n",
            "Running Model:\n",
            "Epoch 1/30\n",
            "17/17 [==============================] - 2s 32ms/step - loss: 1.0261 - acc: 0.4692 - val_loss: 0.7396 - val_acc: 0.7052\n",
            "Epoch 2/30\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.5490 - acc: 0.7733 - val_loss: 0.3482 - val_acc: 0.8690\n",
            "Epoch 3/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.3072 - acc: 0.8730 - val_loss: 0.2595 - val_acc: 0.9037\n",
            "Epoch 4/30\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.2106 - acc: 0.9192 - val_loss: 0.2224 - val_acc: 0.8960\n",
            "Epoch 5/30\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.1506 - acc: 0.9432 - val_loss: 0.1960 - val_acc: 0.9075\n",
            "Epoch 6/30\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1127 - acc: 0.9591 - val_loss: 0.1993 - val_acc: 0.9056\n",
            "Epoch 7/30\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.0811 - acc: 0.9687 - val_loss: 0.1961 - val_acc: 0.9133\n",
            "Epoch 8/30\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.0595 - acc: 0.9769 - val_loss: 0.2087 - val_acc: 0.9210\n",
            "Epoch 9/30\n",
            "17/17 [==============================] - 0s 30ms/step - loss: 0.0556 - acc: 0.9783 - val_loss: 0.2471 - val_acc: 0.9017\n",
            "Epoch 10/30\n",
            "17/17 [==============================] - 0s 25ms/step - loss: 0.0513 - acc: 0.9798 - val_loss: 0.2532 - val_acc: 0.9056\n",
            "Epoch 11/30\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.0406 - acc: 0.9827 - val_loss: 0.2360 - val_acc: 0.9056\n",
            "Epoch 12/30\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.0380 - acc: 0.9836 - val_loss: 0.2438 - val_acc: 0.9094\n",
            "Epoch 13/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0357 - acc: 0.9836 - val_loss: 0.2346 - val_acc: 0.9171\n",
            "Epoch 14/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0354 - acc: 0.9836 - val_loss: 0.2438 - val_acc: 0.9133\n",
            "Epoch 15/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0347 - acc: 0.9836 - val_loss: 0.2453 - val_acc: 0.9133\n",
            "Epoch 16/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0339 - acc: 0.9836 - val_loss: 0.2567 - val_acc: 0.9133\n",
            "Epoch 17/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0335 - acc: 0.9836 - val_loss: 0.2631 - val_acc: 0.9171\n",
            "Epoch 18/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0335 - acc: 0.9836 - val_loss: 0.2746 - val_acc: 0.9133\n",
            "Epoch 19/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0331 - acc: 0.9836 - val_loss: 0.2681 - val_acc: 0.9133\n",
            "Epoch 20/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0330 - acc: 0.9836 - val_loss: 0.2772 - val_acc: 0.9191\n",
            "Epoch 21/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0330 - acc: 0.9836 - val_loss: 0.2754 - val_acc: 0.9171\n",
            "Epoch 22/30\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.0332 - acc: 0.9836 - val_loss: 0.3070 - val_acc: 0.9171\n",
            "Epoch 23/30\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.0331 - acc: 0.9836 - val_loss: 0.3185 - val_acc: 0.9114\n",
            "Epoch 24/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0330 - acc: 0.9836 - val_loss: 0.3068 - val_acc: 0.9133\n",
            "Epoch 25/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0331 - acc: 0.9836 - val_loss: 0.3190 - val_acc: 0.9094\n",
            "Epoch 26/30\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0341 - acc: 0.9832 - val_loss: 0.3153 - val_acc: 0.9133\n",
            "Epoch 27/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0410 - acc: 0.9812 - val_loss: 0.3476 - val_acc: 0.9094\n",
            "Epoch 28/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0471 - acc: 0.9783 - val_loss: 0.2916 - val_acc: 0.9191\n",
            "Epoch 29/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0564 - acc: 0.9755 - val_loss: 0.4085 - val_acc: 0.8998\n",
            "Epoch 30/30\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0502 - acc: 0.9779 - val_loss: 0.2863 - val_acc: 0.9056\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7fc5707a6b50>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The stopwords don't seem to make much of a difference, but this also did really well. Maybe the irrelevance of the stopwords is due to the distinction between the different categories so the model has an easier time determining which words are most relevant"
      ],
      "metadata": {
        "id": "6drEaFG0rYGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_learning(w2v_model, newsgroups_diff_cats, 300, ENGLISH_STOP_WORDS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kY1F5qPrnmh",
        "outputId": "96d86ed4-085e-448b-bebe-b385363b3dfa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Dimension:  300\n",
            "Converted 13823 words (6177 misses)\n",
            "Running Model:\n",
            "Epoch 1/30\n",
            "17/17 [==============================] - 3s 67ms/step - loss: 0.9850 - acc: 0.4986 - val_loss: 0.7036 - val_acc: 0.6782\n",
            "Epoch 2/30\n",
            "17/17 [==============================] - 0s 23ms/step - loss: 0.4753 - acc: 0.8041 - val_loss: 0.3040 - val_acc: 0.8671\n",
            "Epoch 3/30\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.2690 - acc: 0.8961 - val_loss: 0.3145 - val_acc: 0.8651\n",
            "Epoch 4/30\n",
            "17/17 [==============================] - 0s 27ms/step - loss: 0.2316 - acc: 0.9167 - val_loss: 0.2532 - val_acc: 0.8921\n",
            "Epoch 5/30\n",
            "17/17 [==============================] - 0s 30ms/step - loss: 0.1292 - acc: 0.9538 - val_loss: 0.2661 - val_acc: 0.8940\n",
            "Epoch 6/30\n",
            "17/17 [==============================] - 0s 26ms/step - loss: 0.0952 - acc: 0.9620 - val_loss: 0.2592 - val_acc: 0.8940\n",
            "Epoch 7/30\n",
            "17/17 [==============================] - 0s 23ms/step - loss: 0.0706 - acc: 0.9687 - val_loss: 0.2698 - val_acc: 0.8940\n",
            "Epoch 8/30\n",
            "17/17 [==============================] - 1s 32ms/step - loss: 0.0571 - acc: 0.9740 - val_loss: 0.2882 - val_acc: 0.8940\n",
            "Epoch 9/30\n",
            "17/17 [==============================] - 1s 39ms/step - loss: 0.0517 - acc: 0.9774 - val_loss: 0.3083 - val_acc: 0.8902\n",
            "Epoch 10/30\n",
            "17/17 [==============================] - 0s 25ms/step - loss: 0.0508 - acc: 0.9803 - val_loss: 0.3287 - val_acc: 0.9056\n",
            "Epoch 11/30\n",
            "17/17 [==============================] - 0s 24ms/step - loss: 0.0390 - acc: 0.9827 - val_loss: 0.3225 - val_acc: 0.9056\n",
            "Epoch 12/30\n",
            "17/17 [==============================] - 0s 23ms/step - loss: 0.0395 - acc: 0.9817 - val_loss: 0.4070 - val_acc: 0.8844\n",
            "Epoch 13/30\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.0434 - acc: 0.9822 - val_loss: 0.3951 - val_acc: 0.8979\n",
            "Epoch 14/30\n",
            "17/17 [==============================] - 0s 23ms/step - loss: 0.0363 - acc: 0.9832 - val_loss: 0.3920 - val_acc: 0.8998\n",
            "Epoch 15/30\n",
            "17/17 [==============================] - 0s 24ms/step - loss: 0.0356 - acc: 0.9832 - val_loss: 0.3676 - val_acc: 0.8940\n",
            "Epoch 16/30\n",
            "17/17 [==============================] - 0s 24ms/step - loss: 0.0347 - acc: 0.9832 - val_loss: 0.3634 - val_acc: 0.8960\n",
            "Epoch 17/30\n",
            "17/17 [==============================] - 0s 23ms/step - loss: 0.0356 - acc: 0.9827 - val_loss: 0.5519 - val_acc: 0.8748\n",
            "Epoch 18/30\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.0480 - acc: 0.9798 - val_loss: 0.4075 - val_acc: 0.8863\n",
            "Epoch 19/30\n",
            "17/17 [==============================] - 0s 24ms/step - loss: 0.0376 - acc: 0.9827 - val_loss: 0.4362 - val_acc: 0.8825\n",
            "Epoch 20/30\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.0409 - acc: 0.9808 - val_loss: 0.4103 - val_acc: 0.8998\n",
            "Epoch 21/30\n",
            "17/17 [==============================] - 0s 23ms/step - loss: 0.0349 - acc: 0.9832 - val_loss: 0.4436 - val_acc: 0.8902\n",
            "Epoch 22/30\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.0342 - acc: 0.9832 - val_loss: 0.4303 - val_acc: 0.9017\n",
            "Epoch 23/30\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.0338 - acc: 0.9832 - val_loss: 0.4438 - val_acc: 0.9037\n",
            "Epoch 24/30\n",
            "17/17 [==============================] - 0s 23ms/step - loss: 0.0332 - acc: 0.9832 - val_loss: 0.4603 - val_acc: 0.8998\n",
            "Epoch 25/30\n",
            "17/17 [==============================] - 0s 23ms/step - loss: 0.0333 - acc: 0.9832 - val_loss: 0.4718 - val_acc: 0.8960\n",
            "Epoch 26/30\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.0331 - acc: 0.9832 - val_loss: 0.4867 - val_acc: 0.8998\n",
            "Epoch 27/30\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.0333 - acc: 0.9832 - val_loss: 0.4907 - val_acc: 0.8979\n",
            "Epoch 28/30\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.0326 - acc: 0.9832 - val_loss: 0.5006 - val_acc: 0.8940\n",
            "Epoch 29/30\n",
            "17/17 [==============================] - 0s 24ms/step - loss: 0.0332 - acc: 0.9832 - val_loss: 0.5039 - val_acc: 0.8979\n",
            "Epoch 30/30\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.0328 - acc: 0.9832 - val_loss: 0.5096 - val_acc: 0.8979\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7fc57016fbe0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interestingly, the word2vec model did slightly worse on the validation accuracy than the glove model"
      ],
      "metadata": {
        "id": "z3TAdW9ys0BS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The word2vec model didn't make much headways either"
      ],
      "metadata": {
        "id": "OwG6pkHcr2iD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Similar Data"
      ],
      "metadata": {
        "id": "S92hXQK2r7DM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "same_cats = ['comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware','comp.windows.x']\n",
        "newsgroups_same_cats = fetch_20newsgroups(subset='all',categories=same_cats, remove=('headers', 'footers', 'quotes'))"
      ],
      "metadata": {
        "id": "cKBk_G0cr8kQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_learning(glove_model, newsgroups_same_cats, 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nNpqWjIs8Mq",
        "outputId": "bcadcfad-01a3-442d-8508-5cd0bd21c71b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Dimension:  200\n",
            "Converted 12007 words (7993 misses)\n",
            "Running Model:\n",
            "Epoch 1/30\n",
            "31/31 [==============================] - 3s 31ms/step - loss: 1.6234 - acc: 0.2129 - val_loss: 1.5986 - val_acc: 0.2587\n",
            "Epoch 2/30\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 1.5490 - acc: 0.3003 - val_loss: 1.3950 - val_acc: 0.4151\n",
            "Epoch 3/30\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 1.3485 - acc: 0.3736 - val_loss: 1.2666 - val_acc: 0.4540\n",
            "Epoch 4/30\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 1.1747 - acc: 0.4792 - val_loss: 1.1157 - val_acc: 0.5072\n",
            "Epoch 5/30\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.9825 - acc: 0.5735 - val_loss: 1.0135 - val_acc: 0.5736\n",
            "Epoch 6/30\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.8054 - acc: 0.6611 - val_loss: 1.0167 - val_acc: 0.5930\n",
            "Epoch 7/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.6581 - acc: 0.7271 - val_loss: 1.0728 - val_acc: 0.5900\n",
            "Epoch 8/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.5175 - acc: 0.8019 - val_loss: 1.1509 - val_acc: 0.6033\n",
            "Epoch 9/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.3944 - acc: 0.8464 - val_loss: 1.0579 - val_acc: 0.6309\n",
            "Epoch 10/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.2757 - acc: 0.9047 - val_loss: 1.2000 - val_acc: 0.6339\n",
            "Epoch 11/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.1891 - acc: 0.9359 - val_loss: 1.4206 - val_acc: 0.6125\n",
            "Epoch 12/30\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.1501 - acc: 0.9537 - val_loss: 1.3849 - val_acc: 0.6513\n",
            "Epoch 13/30\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.1045 - acc: 0.9673 - val_loss: 1.9031 - val_acc: 0.5757\n",
            "Epoch 14/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.1239 - acc: 0.9558 - val_loss: 1.4365 - val_acc: 0.6524\n",
            "Epoch 15/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0728 - acc: 0.9767 - val_loss: 1.5664 - val_acc: 0.6380\n",
            "Epoch 16/30\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.0618 - acc: 0.9806 - val_loss: 1.7246 - val_acc: 0.6544\n",
            "Epoch 17/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0555 - acc: 0.9796 - val_loss: 1.7120 - val_acc: 0.6462\n",
            "Epoch 18/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0694 - acc: 0.9747 - val_loss: 1.8079 - val_acc: 0.6370\n",
            "Epoch 19/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0634 - acc: 0.9770 - val_loss: 1.7262 - val_acc: 0.6309\n",
            "Epoch 20/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0546 - acc: 0.9808 - val_loss: 1.8057 - val_acc: 0.6483\n",
            "Epoch 21/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0637 - acc: 0.9770 - val_loss: 2.3755 - val_acc: 0.5736\n",
            "Epoch 22/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0812 - acc: 0.9673 - val_loss: 1.9371 - val_acc: 0.6125\n",
            "Epoch 23/30\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.1382 - acc: 0.9517 - val_loss: 1.5754 - val_acc: 0.6401\n",
            "Epoch 24/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0901 - acc: 0.9686 - val_loss: 1.6186 - val_acc: 0.6595\n",
            "Epoch 25/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0565 - acc: 0.9790 - val_loss: 1.8133 - val_acc: 0.6329\n",
            "Epoch 26/30\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.0526 - acc: 0.9819 - val_loss: 1.9971 - val_acc: 0.6227\n",
            "Epoch 27/30\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.1248 - acc: 0.9525 - val_loss: 1.5054 - val_acc: 0.6564\n",
            "Epoch 28/30\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.0679 - acc: 0.9780 - val_loss: 1.7502 - val_acc: 0.6544\n",
            "Epoch 29/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0476 - acc: 0.9816 - val_loss: 1.8773 - val_acc: 0.6554\n",
            "Epoch 30/30\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.0475 - acc: 0.9824 - val_loss: 1.9196 - val_acc: 0.6564\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7fc534701fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the parallel opposite conclusion of the different categories, the model had a very hard time distinguishing between the similar categories - only acheiving a validation accuracy of 65%."
      ],
      "metadata": {
        "id": "skt0GhoqtCh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_learning(glove_model, newsgroups_same_cats, 200, ENGLISH_STOP_WORDS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5zitZH2sRHN",
        "outputId": "3cff925a-dc85-4566-a383-fd91bce0378b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Dimension:  200\n",
            "Converted 11770 words (8230 misses)\n",
            "Running Model:\n",
            "Epoch 1/30\n",
            "31/31 [==============================] - 2s 23ms/step - loss: 1.6128 - acc: 0.2331 - val_loss: 1.5597 - val_acc: 0.3241\n",
            "Epoch 2/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.4109 - acc: 0.3550 - val_loss: 1.2876 - val_acc: 0.3885\n",
            "Epoch 3/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.1920 - acc: 0.4633 - val_loss: 1.1487 - val_acc: 0.5051\n",
            "Epoch 4/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.0059 - acc: 0.5686 - val_loss: 1.0905 - val_acc: 0.5460\n",
            "Epoch 5/30\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.8028 - acc: 0.6708 - val_loss: 1.0353 - val_acc: 0.5879\n",
            "Epoch 6/30\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 0.6142 - acc: 0.7557 - val_loss: 0.9798 - val_acc: 0.6207\n",
            "Epoch 7/30\n",
            "31/31 [==============================] - 1s 24ms/step - loss: 0.4325 - acc: 0.8423 - val_loss: 1.0475 - val_acc: 0.6431\n",
            "Epoch 8/30\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.3192 - acc: 0.8914 - val_loss: 1.1171 - val_acc: 0.6524\n",
            "Epoch 9/30\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.2378 - acc: 0.9244 - val_loss: 1.1245 - val_acc: 0.6718\n",
            "Epoch 10/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.1542 - acc: 0.9517 - val_loss: 1.4123 - val_acc: 0.6391\n",
            "Epoch 11/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.1294 - acc: 0.9573 - val_loss: 1.3174 - val_acc: 0.6605\n",
            "Epoch 12/30\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.0913 - acc: 0.9727 - val_loss: 1.4697 - val_acc: 0.6605\n",
            "Epoch 13/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0849 - acc: 0.9729 - val_loss: 1.4629 - val_acc: 0.6728\n",
            "Epoch 14/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0763 - acc: 0.9747 - val_loss: 1.4823 - val_acc: 0.6636\n",
            "Epoch 15/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0756 - acc: 0.9752 - val_loss: 1.4933 - val_acc: 0.6626\n",
            "Epoch 16/30\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.0874 - acc: 0.9688 - val_loss: 1.5260 - val_acc: 0.6534\n",
            "Epoch 17/30\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.0852 - acc: 0.9693 - val_loss: 1.7939 - val_acc: 0.6278\n",
            "Epoch 18/30\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.0849 - acc: 0.9686 - val_loss: 1.4851 - val_acc: 0.6748\n",
            "Epoch 19/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0855 - acc: 0.9668 - val_loss: 1.8122 - val_acc: 0.6217\n",
            "Epoch 20/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.1117 - acc: 0.9617 - val_loss: 1.7223 - val_acc: 0.6462\n",
            "Epoch 21/30\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0788 - acc: 0.9757 - val_loss: 1.5975 - val_acc: 0.6697\n",
            "Epoch 22/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0631 - acc: 0.9780 - val_loss: 1.6741 - val_acc: 0.6718\n",
            "Epoch 23/30\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.0965 - acc: 0.9640 - val_loss: 1.8024 - val_acc: 0.6493\n",
            "Epoch 24/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0725 - acc: 0.9747 - val_loss: 1.6082 - val_acc: 0.6759\n",
            "Epoch 25/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0645 - acc: 0.9775 - val_loss: 1.5941 - val_acc: 0.6789\n",
            "Epoch 26/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0525 - acc: 0.9780 - val_loss: 1.6825 - val_acc: 0.6646\n",
            "Epoch 27/30\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.0482 - acc: 0.9811 - val_loss: 1.8048 - val_acc: 0.6605\n",
            "Epoch 28/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0459 - acc: 0.9806 - val_loss: 1.7593 - val_acc: 0.6759\n",
            "Epoch 29/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0464 - acc: 0.9790 - val_loss: 1.7531 - val_acc: 0.6800\n",
            "Epoch 30/30\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0476 - acc: 0.9793 - val_loss: 1.7628 - val_acc: 0.6861\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7fc53454bfa0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing the stopwords helped slightly"
      ],
      "metadata": {
        "id": "0JPztiv-tWrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_learning(w2v_model, newsgroups_same_cats, 200, ENGLISH_STOP_WORDS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q98Fo0AhtSRu",
        "outputId": "764501af-1bce-42ec-aff3-63385bffdb23"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Dimension:  300\n",
            "Converted 10149 words (9851 misses)\n",
            "Running Model:\n",
            "Epoch 1/30\n",
            "31/31 [==============================] - 3s 27ms/step - loss: 1.6060 - acc: 0.2295 - val_loss: 1.5854 - val_acc: 0.2975\n",
            "Epoch 2/30\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 1.4309 - acc: 0.3754 - val_loss: 1.2869 - val_acc: 0.4601\n",
            "Epoch 3/30\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 1.1264 - acc: 0.5101 - val_loss: 1.1303 - val_acc: 0.5266\n",
            "Epoch 4/30\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.8882 - acc: 0.6514 - val_loss: 1.0333 - val_acc: 0.5910\n",
            "Epoch 5/30\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.6686 - acc: 0.7565 - val_loss: 0.9640 - val_acc: 0.6329\n",
            "Epoch 6/30\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 0.5387 - acc: 0.8127 - val_loss: 1.0860 - val_acc: 0.6176\n",
            "Epoch 7/30\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 0.3539 - acc: 0.8845 - val_loss: 1.1468 - val_acc: 0.6299\n",
            "Epoch 8/30\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.2415 - acc: 0.9254 - val_loss: 1.1091 - val_acc: 0.6452\n",
            "Epoch 9/30\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.1747 - acc: 0.9466 - val_loss: 1.1913 - val_acc: 0.6513\n",
            "Epoch 10/30\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.1256 - acc: 0.9622 - val_loss: 1.2843 - val_acc: 0.6524\n",
            "Epoch 11/30\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.0893 - acc: 0.9711 - val_loss: 1.3896 - val_acc: 0.6575\n",
            "Epoch 12/30\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.0782 - acc: 0.9750 - val_loss: 1.5135 - val_acc: 0.6534\n",
            "Epoch 13/30\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.0788 - acc: 0.9716 - val_loss: 1.5080 - val_acc: 0.6605\n",
            "Epoch 14/30\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.0656 - acc: 0.9780 - val_loss: 1.5486 - val_acc: 0.6554\n",
            "Epoch 15/30\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.0884 - acc: 0.9706 - val_loss: 1.8843 - val_acc: 0.6258\n",
            "Epoch 16/30\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.1094 - acc: 0.9596 - val_loss: 2.1164 - val_acc: 0.5716\n",
            "Epoch 17/30\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.1266 - acc: 0.9563 - val_loss: 1.5147 - val_acc: 0.6483\n",
            "Epoch 18/30\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.0759 - acc: 0.9696 - val_loss: 1.5996 - val_acc: 0.6524\n",
            "Epoch 19/30\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.0614 - acc: 0.9775 - val_loss: 1.6752 - val_acc: 0.6605\n",
            "Epoch 20/30\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.0517 - acc: 0.9816 - val_loss: 1.7533 - val_acc: 0.6687\n",
            "Epoch 21/30\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.0510 - acc: 0.9806 - val_loss: 1.8117 - val_acc: 0.6677\n",
            "Epoch 22/30\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.0548 - acc: 0.9785 - val_loss: 1.7717 - val_acc: 0.6646\n",
            "Epoch 23/30\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.0480 - acc: 0.9790 - val_loss: 1.8132 - val_acc: 0.6524\n",
            "Epoch 24/30\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.0531 - acc: 0.9788 - val_loss: 1.8719 - val_acc: 0.6585\n",
            "Epoch 25/30\n",
            "31/31 [==============================] - 0s 16ms/step - loss: 0.0623 - acc: 0.9747 - val_loss: 2.0133 - val_acc: 0.6268\n",
            "Epoch 26/30\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.1074 - acc: 0.9627 - val_loss: 1.5984 - val_acc: 0.6544\n",
            "Epoch 27/30\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.0739 - acc: 0.9716 - val_loss: 1.6439 - val_acc: 0.6667\n",
            "Epoch 28/30\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.0568 - acc: 0.9770 - val_loss: 1.7181 - val_acc: 0.6554\n",
            "Epoch 29/30\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.0571 - acc: 0.9780 - val_loss: 1.7230 - val_acc: 0.6789\n",
            "Epoch 30/30\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.0573 - acc: 0.9770 - val_loss: 1.7424 - val_acc: 0.6861\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7fc53451d670>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The word2vec model acted quite similarly to the glove model"
      ],
      "metadata": {
        "id": "jXSRx9lftiR3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "1x4yP3vyxgTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, there was not much substantial change between different iterations of transfer learning. The biggest differences came from the similarity of the categories in the dataset. Also, when trained on all 20 categories the model also did better. But adding in the top chi2 words, using different models, removing stopwords all didn't significantly improve the model."
      ],
      "metadata": {
        "id": "GXbHQoILxGVr"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}